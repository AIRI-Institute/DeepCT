{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import yaml\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "# sys.path.append('../../')\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from omegaconf import OmegaConf\n",
    "import itertools\n",
    "from selene_sdk.utils import load_path, parse_configs_and_run\n",
    "from selene_sdk.utils.config_utils import module_from_dir, module_from_file\n",
    "from selene_sdk.utils.config import instantiate\n",
    "from src.dataset import EncodeDataset, LargeRandomSampler, encode_worker_init_fn\n",
    "from src.transforms import *\n",
    "from src.utils import interval_from_line\n",
    "# from torchvision import transforms\n",
    "# from torchmetrics import BinnedAveragePrecision, AveragePrecision, Accuracy\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import copy\n",
    "from src.utils import expand_dims\n",
    "import gc\n",
    "gc.enable()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "\n",
    "from src.metrics import jaccard_score, threshold_wrapper\n",
    "from sklearn.metrics import average_precision_score\n",
    "from selene_sdk.utils.performance_metrics import compute_score\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "path = 'model_configs/biox_dnase_multi_ct_skf_crossval.yaml'\n",
    "configs = load_path(path, instantiate=False)\n",
    "configs['dataset']['debug'] = True\n",
    "configs['dataset']['loader_args']['batch_size'] = 20"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "from src.deepct_model_multi_ct import DeepCT\n",
    "\n",
    "model = DeepCT(**configs['model']['class_args'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "from selene_sdk.utils.config_utils import get_full_dataset, get_full_dataloader\n",
    "\n",
    "# full_dataset = get_full_dataset(configs)\n",
    "full_dl = get_full_dataloader(configs)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DEBUG MODE ON: 1000\n",
      "full_dataloader len: 410\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "dataset_info = configs[\"dataset\"]\n",
    "\n",
    "# all intervals\n",
    "genome_intervals = []\n",
    "with open(dataset_info[\"sampling_intervals_path\"])  as f:\n",
    "    for line in f:\n",
    "        chrom, start, end = interval_from_line(line)\n",
    "        genome_intervals.append((chrom, start, end))\n",
    "\n",
    "# bedug mode\n",
    "if dataset_info['debug']:\n",
    "    genome_intervals = random.sample(genome_intervals, k=1000)\n",
    "    print(\"DEBUG MODE ON:\", len(genome_intervals))\n",
    "\n",
    "with open(dataset_info[\"distinct_features_path\"]) as f:\n",
    "    distinct_features = list(map(lambda x: x.rstrip(), f.readlines()))\n",
    "    \n",
    "with open(dataset_info[\"target_features_path\"]) as f:\n",
    "    target_features = list(map(lambda x: x.rstrip(), f.readlines()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DEBUG MODE ON: 1000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Стратификация по CT"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "all_targets_mean = np.load('/home/thurs/DeepCT/results/ct_mean_targets.npy')\n",
    "print(len(all_targets_mean))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "631\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "plt.hist(all_targets_mean);"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "y_cat = pd.cut(all_targets_mean, 10, labels=range(10))\n",
    "y_cat = np.array(y_cat)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "plt.hist(y_cat);"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "from sklearn.model_selection import KFold, GroupKFold, StratifiedKFold\n",
    "\n",
    "# Stratified k-fold\n",
    "ct_range = range(configs['model']['class_args']['n_cell_types'])\n",
    "n_folds = 10\n",
    "ct_splits = []\n",
    "ct_values_splits = []\n",
    "seeds = [1950, 1957, 1962, 1970, 1980, 1989, 2008, 2012, 2017, 2021]\n",
    "for fold in range(n_folds):\n",
    "    skf = StratifiedKFold(n_folds, shuffle=True, random_state=seeds[fold])\n",
    "    tmp = []\n",
    "    tmp_vals = []\n",
    "    for train_idx, test_idx in skf.split(ct_range, y_cat):\n",
    "        tmp.append(test_idx)\n",
    "        tmp_vals.append((y_cat[train_idx], y_cat[test_idx]))\n",
    "    ct_splits.append(tmp)\n",
    "    ct_values_splits.append(tmp_vals)\n",
    "    \n",
    "len(ct_splits)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "[len(c) for c in ct_splits]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[10, 10, 10, 10, 10, 10, 10, 10, 10, 10]"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "[(len(c[0]), len(c[1])) for c in ct_values_splits[0]]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(567, 64),\n",
       " (568, 63),\n",
       " (568, 63),\n",
       " (568, 63),\n",
       " (568, 63),\n",
       " (568, 63),\n",
       " (568, 63),\n",
       " (568, 63),\n",
       " (568, 63),\n",
       " (568, 63)]"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "[(sum(c[0]), sum(c[1])) for c in ct_values_splits[0]]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(1200, 139),\n",
       " (1208, 131),\n",
       " (1202, 137),\n",
       " (1202, 137),\n",
       " (1202, 137),\n",
       " (1207, 132),\n",
       " (1206, 133),\n",
       " (1206, 133),\n",
       " (1209, 130),\n",
       " (1209, 130)]"
      ]
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "# np.save('/home/thurs/DeepCT/results/ct_stratified_ids_k10.npy', ct_splits)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# ct_splits = np.load('/home/thurs/DeepCT/results/ct_stratified_ids_k10.npy', allow_pickle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=10, figsize=(40, 5))\n",
    "\n",
    "for i in range(10):\n",
    "    axes[i].hist(ct_values_splits[i][0], bins=10)\n",
    "    axes[i].hist(ct_values_splits[i][1], bins=10)\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2880x360 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "ct_masks = ct_splits[0]\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction='sum')\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr = 0.0001, weight_decay = 1e-6)\n",
    "\n",
    "for batch in full_dl:\n",
    "    sequence_batch, cell_type_batch, targets, target_mask = batch\n",
    "\n",
    "     # val mask\n",
    "    target_mask_tr = target_mask.clone()\n",
    "    target_mask_tr[:, ct_masks[0]] = False\n",
    "    target_mask_val = ~target_mask_tr\n",
    "    print(target_mask_tr.sum(), target_mask_val.sum())\n",
    "\n",
    "    # compute a baseline\n",
    "    baseline = (targets * target_mask_tr).sum(axis=1) / target_mask_tr.sum(axis=1)\n",
    "    baseline = torch.repeat_interleave(baseline.unsqueeze(1), 631, dim=1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(sequence_batch, cell_type_batch)\n",
    "        criterion.weight = target_mask_val\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        if criterion.reduction == \"sum\":\n",
    "            loss = loss / criterion.weight.sum()\n",
    "\n",
    "        predictions = torch.sigmoid(outputs)\n",
    "        predictions = predictions.view(-1, predictions.shape[-1])\n",
    "        targets = targets.view(-1, targets.shape[-1])\n",
    "        baseline = baseline.view(-1, baseline.shape[-1])\n",
    "        target_mask = target_mask_val.view(-1, target_mask_val.shape[-1])\n",
    "\n",
    "    break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(11340) tensor(1280)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "predictions"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.4163],\n",
       "        [0.3897],\n",
       "        [0.3891],\n",
       "        ...,\n",
       "        [0.3596],\n",
       "        [0.3802],\n",
       "        [0.3543]])"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "baseline"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.0018],\n",
       "        [0.0018],\n",
       "        [0.0018],\n",
       "        ...,\n",
       "        [0.0423],\n",
       "        [0.0423],\n",
       "        [0.0423]])"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "targets"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "# all_predictions = expand_dims(np.concatenate(predictions))\n",
    "# all_targets = expand_dims(np.concatenate(targets))\n",
    "# all_baselines = expand_dims(np.concatenate(baseline))\n",
    "# all_target_masks = expand_dims(np.concatenate(target_mask))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "average_scores = _compute_metrics(\n",
    "    predictions, targets, target_mask, log_prefix=\"validation\"\n",
    ")\n",
    "baselines_scores = _compute_baseline_score(\n",
    "    baseline, targets, target_mask, log_prefix=\"validation\"\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Стратификация по seq"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "mean_target_np = np.load(f'/home/thurs/DeepCT/results/all_targets_mean.npy')\n",
    "idx_np = np.load(f'/home/thurs/DeepCT/results/all_idx.npy')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "len(mean_target_np), len(idx_np)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(11576175, 11576175)"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def create_split_loaders(configs, full_dataset, split):\n",
    "    \"\"\"\n",
    "    Called for each split, this creates a two DataLoaders for each split. \n",
    "    One DataLoader for the samples in the training folds and one DataLoader \n",
    "    for the samples in the validation fold.\n",
    "    \"\"\"\n",
    "    dataset_info = configs[\"dataset\"]\n",
    "    # current_fold = configs[\"dataset\"]['dataset_args']['fold']\n",
    "    # print('current fold:', current_fold)\n",
    "\n",
    "    train_folds_idx = split[0]\n",
    "    valid_folds_idx = split[1]\n",
    "    current_fold_idx = np.append(train_folds_idx, valid_folds_idx)\n",
    "\n",
    "    train_subset = torch.utils.data.Subset(\n",
    "        full_dataset, \n",
    "        current_fold_idx\n",
    "        )\n",
    "\n",
    "    val_subset = torch.utils.data.Subset(\n",
    "        full_dataset, \n",
    "        valid_folds_idx\n",
    "        )\n",
    "    val_transform = instantiate(dataset_info[\"val_transform\"])\n",
    "    val_subset.dataset.transform = val_transform\n",
    "\n",
    "    module = None\n",
    "    if os.path.isdir(dataset_info[\"path\"]):\n",
    "        module = module_from_dir(dataset_info[\"path\"])\n",
    "    else:\n",
    "        module = module_from_file(dataset_info[\"path\"])\n",
    "\n",
    "    train_sampler_class = getattr(module, dataset_info[\"sampler_class\"])\n",
    "    gen = torch.Generator()\n",
    "    gen.manual_seed(configs[\"random_seed\"])\n",
    "    train_sampler = train_sampler_class(\n",
    "        train_subset, replacement=False, generator=gen\n",
    "    )\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_subset,\n",
    "        batch_size=dataset_info[\"loader_args\"][\"batch_size\"],\n",
    "        num_workers=dataset_info[\"loader_args\"][\"num_workers\"],\n",
    "        worker_init_fn=module.subset_encode_worker_init_fn,\n",
    "        sampler=train_sampler,\n",
    "    )\n",
    "\n",
    "    val_sampler_class = getattr(module, dataset_info[\"validation_sampler_class\"])\n",
    "    gen = torch.Generator()\n",
    "    gen.manual_seed(configs[\"random_seed\"])\n",
    "\n",
    "    val_sampler = val_sampler_class(\n",
    "        data_source=val_subset, \n",
    "        num_samples=dataset_info['validation_sampler_args']['num_samples'], \n",
    "        generator=gen\n",
    "    )\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "            val_subset,\n",
    "            batch_size=configs['dataset'][\"loader_args\"][\"batch_size\"],\n",
    "            num_workers=configs['dataset'][\"loader_args\"][\"num_workers\"],\n",
    "            worker_init_fn=module.subset_encode_worker_init_fn,\n",
    "            sampler=val_sampler,\n",
    "        )\n",
    "\n",
    "    return (train_loader, val_loader) \n",
    "\n",
    "\n",
    "def get_all_split_loaders(dataset, cv_splits):\n",
    "    \"\"\"Create DataLoaders for each split.\n",
    "\n",
    "    Keyword arguments:\n",
    "    dataset -- Dataset to sample from.\n",
    "    cv_splits -- Array containing indices of samples to \n",
    "                 be used in each fold for each split.\n",
    "    aug_count -- Number of variations for each sample in dataset.\n",
    "    batch_size -- batch size.\n",
    "    \n",
    "    \"\"\"\n",
    "    split_samplers = []\n",
    "    \n",
    "    for i in range(len(cv_splits)):\n",
    "        split_samplers.append(\n",
    "            create_split_loaders(\n",
    "                configs,\n",
    "                dataset,\n",
    "                cv_splits[i]\n",
    "                )\n",
    "        )\n",
    "    return split_samplers\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "train_loader_0, val_loader_0 = create_split_loaders(configs, full_dataset, splits[0])\n",
    "len(train_loader_0), len(val_loader_0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(50, 5)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "dataloaders = get_all_split_loaders(full_dataset, splits)\n",
    "len(dataloaders)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "dataloaders[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x7fc52b037710>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7fc52b087d30>)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "for i, batch in tqdm(enumerate(dataloaders[0][1])):\n",
    "    sequence_batch, cell_type_batch, targets, target_mask = batch\n",
    "    break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "target_mask.sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(12620)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# torch.masked_select(target_mask, torch.tensor(ct_masks[0]))\n",
    "\n",
    "target_mask_tr = target_mask.clone()\n",
    "target_mask_tr[:, ct_masks[0].min(): ct_masks[0].max()+1] = False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "target_mask_tr.sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(11340)"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "def train(model, batch, fold):\n",
    "    \"\"\"\n",
    "    Trains the model on a batch of data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The training loss.\n",
    "\n",
    "    \"\"\"    \n",
    "    # retrieved_seq, cell_type, target, target_mask\n",
    "    sequence_batch = batch[0]#.to(device)\n",
    "    cell_type_batch = batch[1]#.to(device)\n",
    "    targets = batch[2]#.to(device)\n",
    "    target_mask = batch[3]#.to(device)\n",
    "\n",
    "    # make train mask\n",
    "    target_mask_tr = target_mask.clone()\n",
    "    target_mask_tr[:, ct_masks[fold].min(): ct_masks[fold].max()+1] = False\n",
    "\n",
    "    outputs = model(sequence_batch, cell_type_batch)\n",
    "\n",
    "    criterion.weight = target_mask_tr\n",
    "    loss = criterion(outputs, targets)\n",
    "    if criterion.reduction == \"sum\":\n",
    "        loss = loss / criterion.weight.sum()\n",
    "    predictions = torch.sigmoid(outputs)\n",
    "\n",
    "    # predictions = predictions * target_mask_tr\n",
    "    # targets = targets * target_mask_tr\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return (\n",
    "        predictions.detach().numpy(),\n",
    "        targets.detach().numpy(),\n",
    "        target_mask_tr.numpy(),\n",
    "        loss.item(),\n",
    "    )\n",
    "\n",
    "def evaluate(model, batch, target_mask_tr):\n",
    "    \"\"\"\n",
    "    Makes predictions for some labeled input data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_in_batches : list(SamplesBatch)\n",
    "        A list of tuples of the data, where the first element is\n",
    "        the example, and the second element is the label.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple(float, list(numpy.ndarray))\n",
    "        Returns the average loss, and the list of all predictions.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    sequence_batch = batch[0]#.to(device)\n",
    "    cell_type_batch = batch[1]#.to(device)\n",
    "    targets = batch[2]#.to(device)\n",
    "    target_mask = batch[3]#.to(device)\n",
    "    # print('targets', targets.shape)\n",
    "\n",
    "    # val mask\n",
    "    target_mask_val = target_mask.clone()\n",
    "    target_mask_val = ~target_mask_tr\n",
    "\n",
    "    if target_mask_val.shape[0] != targets.shape[0]:\n",
    "        target_mask_val = target_mask_val[:targets.shape[0], ...]\n",
    "\n",
    "    # compure a baseline\n",
    "    baseline = (targets * target_mask_val).sum(axis=1) / target_mask_val.sum(axis=1)\n",
    "    baseline = torch.repeat_interleave(baseline.unsqueeze(1), 631, dim=1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(sequence_batch, cell_type_batch)\n",
    "\n",
    "        criterion.weight = target_mask_val\n",
    "        loss = criterion(outputs, targets)\n",
    "        if criterion.reduction == \"sum\":\n",
    "            loss = loss / criterion.weight.sum()\n",
    "\n",
    "        predictions = torch.sigmoid(outputs)\n",
    "        predictions = predictions.view(-1, predictions.shape[-1])\n",
    "        targets = targets.view(-1, targets.shape[-1])\n",
    "        baseline = baseline.view(-1, baseline.shape[-1])\n",
    "        target_mask = target_mask_val.view(-1, target_mask_val.shape[-1])\n",
    "\n",
    "    return loss, predictions, targets, baseline, target_mask\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss(reduction='sum')\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr = 0.0001, weight_decay = 1e-6)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "from selene_sdk.utils import (\n",
    "    PerformanceMetrics,\n",
    "    initialize_logger,\n",
    "    load_model_from_state_dict,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay,\n",
    "    average_precision_score,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    ")\n",
    "\n",
    "\n",
    "metrics=dict(roc_auc=roc_auc_score, average_precision=average_precision_score)\n",
    "\n",
    "_test_metrics = PerformanceMetrics(\n",
    "            lambda idx: train_batch_loader.dataset.dataset.target_features[idx],\n",
    "            report_gt_feature_n_positives=10,\n",
    "            metrics=metrics,\n",
    "        )\n",
    "\n",
    "print(train_batch_loader.dataset.dataset.target_features[0])\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DNase-seq\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "# train_batch_loader -- batches all samples in training folds.\n",
    "# valid_batch_loader -- batches all samples in validation fold.\n",
    "for fold, (train_batch_loader, valid_batch_loader) in enumerate(dataloaders):\n",
    "    print('fold:', fold, len(train_batch_loader), len(valid_batch_loader))\n",
    "    # Loop through all batches in training folds for a given split.\n",
    "    model.train()\n",
    "    tain_losses = []\n",
    "    for batch in tqdm(train_batch_loader):\n",
    "        # Train model on the training folds in the split.\n",
    "        prediction, target, target_mask, loss = train(model, batch, fold)\n",
    "        tain_losses.append(loss)\n",
    "    print('train loss:', np.average(tain_losses))\n",
    "\n",
    "    # Loop through all batches in validation fold for a given split.\n",
    "    model.eval()\n",
    "    batch_losses = []\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    all_target_masks = []\n",
    "    all_baselines = []\n",
    "    for batch in tqdm(valid_batch_loader):\n",
    "        # Test model on the validation fold in the split.\n",
    "        (\n",
    "            loss,\n",
    "            predictions,\n",
    "            targets,\n",
    "            baseline,\n",
    "            target_masks,\n",
    "        ) = evaluate(model, batch, target_mask_tr)\n",
    "\n",
    "        all_predictions.append(predictions.data.numpy())\n",
    "        all_targets.append(targets.data.numpy())\n",
    "        all_target_masks.append(target_masks.data.numpy())\n",
    "        all_baselines.append(baseline.data.numpy())\n",
    "        batch_losses.append(loss.item())\n",
    "\n",
    "    all_predictions = expand_dims(np.concatenate(all_predictions))\n",
    "    all_targets = expand_dims(np.concatenate(all_targets))\n",
    "    all_baselines = expand_dims(np.concatenate(all_baselines))\n",
    "    all_target_masks = expand_dims(np.concatenate(all_target_masks))\n",
    "\n",
    "    # compute metrics\n",
    "    average_scores = _test_metrics.update(\n",
    "        all_predictions, all_targets, all_target_masks\n",
    "    )\n",
    "    baseline_score = _test_metrics.update(\n",
    "        all_baselines, all_targets, all_target_masks\n",
    "    )\n",
    "\n",
    "    for name, score in average_scores.items():\n",
    "        print(name, score)\n",
    "    for name, score in baseline_score.items():\n",
    "        print(f'baseline_{name}', score)   \n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "fold: 0 50 5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  8%|▊         | 4/50 [00:28<05:16,  6.88s/it]"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Stratified k-fold\n",
    "\n",
    "n_folds = 10\n",
    "skf = StratifiedKFold(n_folds, shuffle=True, random_state=666)\n",
    "\n",
    "splits = []\n",
    "for train_idx, test_idx in k_fold.split(genome_intervals):\n",
    "    splits.append((train_idx, test_idx))\n",
    "\n",
    "ct_masks = np.array_split(range(configs['model']['class_args']['n_cell_types']), n_folds)\n",
    "print([len(c) for c in ct_masks])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "all_targets_mean = np.load('/home/thurs/DeepCT/results/all_targets_mean.npy')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit ('genv': venv)"
  },
  "interpreter": {
   "hash": "7bed6a5b8f0827f7d7f30ba9d7b2c61fcd2f223009d9afc95ff59e669a7c4ade"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}