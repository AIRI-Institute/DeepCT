{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "import yaml\n",
    "import os\n",
    "import sys\n",
    "# sys.path.append('../../')\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from omegaconf import OmegaConf\n",
    "# import torchmetrics\n",
    "# import torch\n",
    "# from torch import nn\n",
    "from selene_sdk.utils import load_path, parse_configs_and_run\n",
    "from selene_sdk.utils.config_utils import module_from_dir, module_from_file\n",
    "from selene_sdk.utils.config import instantiate\n",
    "from src.dataset import EncodeDataset, LargeRandomSampler, encode_worker_init_fn\n",
    "from src.transforms import *\n",
    "from src.utils import interval_from_line\n",
    "# from torchvision import transforms\n",
    "# from torchmetrics import BinnedAveragePrecision, AveragePrecision, Accuracy\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from src.utils import expand_dims\n",
    "import gc\n",
    "gc.enable()\n",
    "\n",
    "from src.metrics import jaccard_score, threshold_wrapper\n",
    "from sklearn.metrics import average_precision_score\n",
    "from selene_sdk.utils.performance_metrics import compute_score\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "path = 'model_configs/biox_dnase_multi_ct_crossval.yaml'\n",
    "configs = load_path(path, instantiate=False)\n",
    "# configs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "configs['dataset']['loader_args']['batch_size'] = 64"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "configs['dataset']['loader_args']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'batch_size': 64, 'num_workers': 16}"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "from sklearn.model_selection import KFold, GroupKFold, StratifiedKFold\n",
    "\n",
    "n_folds = 5\n",
    "k_fold = KFold(n_folds, shuffle=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "ct_mask_range = np.array_split(range(configs['model']['class_args']['n_cell_types']), n_folds)\n",
    "len(ct_mask_range)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "import random\n",
    "from selene_sdk.utils.config_utils import get_fold_idx\n",
    "\n",
    "\n",
    "def get_loaders(configs, output_dir=None, load_test=False):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    if \"sampler\" in configs:\n",
    "        sampler_info = configs[\"sampler\"]\n",
    "        if output_dir is not None:\n",
    "            sampler_info.bind(output_dir=output_dir)\n",
    "        sampler = instantiate(sampler_info)\n",
    "        return sampler\n",
    "    if \"dataset\" in configs:\n",
    "        dataset_info = configs[\"dataset\"]\n",
    "\n",
    "        # all intervals\n",
    "        genome_intervals = []\n",
    "        with open(dataset_info[\"sampling_intervals_path\"])  as f:\n",
    "            for line in f:\n",
    "                chrom, start, end = interval_from_line(line)\n",
    "                genome_intervals.append((chrom, start, end))\n",
    "\n",
    "        # bedug\n",
    "        # genome_intervals = random.sample(genome_intervals, k=20)\n",
    "        # print(\"DEBUG MODE ON:\", len(genome_intervals))\n",
    "\n",
    "        with open(dataset_info[\"distinct_features_path\"]) as f:\n",
    "            distinct_features = list(map(lambda x: x.rstrip(), f.readlines()))\n",
    "\n",
    "        with open(dataset_info[\"target_features_path\"]) as f:\n",
    "            target_features = list(map(lambda x: x.rstrip(), f.readlines()))\n",
    "\n",
    "        module = None\n",
    "        if os.path.isdir(dataset_info[\"path\"]):\n",
    "            module = module_from_dir(dataset_info[\"path\"])\n",
    "        else:\n",
    "            module = module_from_file(dataset_info[\"path\"])\n",
    "\n",
    "        dataset_class = getattr(module, dataset_info[\"class\"])\n",
    "        dataset_info[\"dataset_args\"][\"target_features\"] = target_features\n",
    "        dataset_info[\"dataset_args\"][\"distinct_features\"] = distinct_features\n",
    "\n",
    "        # load train dataset and loader\n",
    "        data_config = dataset_info[\"dataset_args\"].copy()\n",
    "        data_config[\"intervals\"] = genome_intervals\n",
    "\n",
    "        genome_intervals_arr, tr_idx_list, val_idx_list = get_fold_idx(\n",
    "            genome_intervals,  \n",
    "            configs,\n",
    "            )\n",
    "\n",
    "        # train/val split\n",
    "        tr_idx = tr_idx_list[dataset_info[\"dataset_args\"][\"fold\"]]\n",
    "        val_idx = val_idx_list[dataset_info[\"dataset_args\"][\"fold\"]]\n",
    "        train_intervals = genome_intervals_arr[tr_idx].tolist()\n",
    "        val_intervals = genome_intervals_arr[val_idx].tolist()\n",
    "\n",
    "        train_config = dataset_info[\"dataset_args\"].copy()\n",
    "        del train_config['fold']\n",
    "        del train_config['n_folds']\n",
    "        train_config[\"intervals\"] = train_intervals\n",
    "        if \"train_transform\" in dataset_info:\n",
    "            # load transforms\n",
    "            train_transform = instantiate(dataset_info[\"train_transform\"])\n",
    "            train_config[\"transform\"] = train_transform\n",
    "        train_dataset = dataset_class(**train_config)\n",
    "\n",
    "        sampler_class = getattr(module, dataset_info[\"sampler_class\"])\n",
    "        gen = torch.Generator()\n",
    "        gen.manual_seed(configs[\"random_seed\"])\n",
    "        train_sampler = sampler_class(\n",
    "            train_dataset, replacement=False, generator=gen\n",
    "        )\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=dataset_info[\"loader_args\"][\"batch_size\"],\n",
    "            num_workers=dataset_info[\"loader_args\"][\"num_workers\"],\n",
    "            worker_init_fn=module.encode_worker_init_fn,\n",
    "            sampler=train_sampler,\n",
    "        )\n",
    "\n",
    "        # load validation dataset and loader\n",
    "        val_config = dataset_info[\"dataset_args\"].copy()\n",
    "        del val_config['fold']\n",
    "        del val_config['n_folds']\n",
    "        val_config[\"intervals\"] = val_intervals\n",
    "        if \"val_transform\" in dataset_info:\n",
    "            # load transforms\n",
    "            val_transform = instantiate(dataset_info[\"val_transform\"])\n",
    "            val_config[\"transform\"] = val_transform\n",
    "        val_dataset = dataset_class(**val_config)\n",
    "\n",
    "        val_loader = torch.utils.data.DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=dataset_info[\"loader_args\"][\"batch_size\"],\n",
    "            num_workers=dataset_info[\"loader_args\"][\"num_workers\"],\n",
    "            worker_init_fn=module.encode_worker_init_fn,\n",
    "        )\n",
    "\n",
    "        out = {\n",
    "            'genome_intervals': genome_intervals_arr, \n",
    "            'train_idx': tr_idx_list,\n",
    "            'val_idx': val_idx_list,\n",
    "            'train_loader': train_loader, \n",
    "            'val_loader': val_loader,\n",
    "        }\n",
    "\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# from selene_sdk.utils.config_utils import get_loaders\n",
    "\n",
    "out = get_loaders(configs)\n",
    "genome_intervals_arr = out['genome_intervals'] \n",
    "tr_idx_list = out['train_idx']\n",
    "val_idx_list = out['val_idx']\n",
    "train_loader = out['train_loader']\n",
    "val_loader = out['val_loader']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "len(train_loader), len(val_loader)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(143990, 36889)"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "batch_size = val_loader.batch_size\n",
    "print(batch_size)\n",
    "n_cell_types = configs['model']['class_args']['n_cell_types']\n",
    "# boix_target_features = val_loader.target_features\n",
    "# boix_track_matrix = val_loader._feature_indices_by_cell_type_index"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "###\n",
    "# fold = 1\n",
    "\n",
    "np.random.seed(14)\n",
    "n_features = 1\n",
    "\n",
    "\n",
    "for fold in range(n_folds):\n",
    "    print(fold)\n",
    "    gts = []\n",
    "    mean_preds = []\n",
    "    masks = []\n",
    "    for sample in tqdm(val_loader):\n",
    "        batch = copy.deepcopy(sample)\n",
    "        sequence_batch, _, targets, target_mask = batch\n",
    "        del sample\n",
    "\n",
    "        # make val mask\n",
    "        target_mask_tr = target_mask.clone()\n",
    "        target_mask_tr[:, ct_mask_range[fold][0]: ct_mask_range[fold][-1]] = False\n",
    "        # val mask\n",
    "        target_mask_val = ~target_mask_tr\n",
    "        masked_targets = targets * target_mask_val\n",
    "\n",
    "        1/0\n",
    "\n",
    "        mean_seq_val = (targets).sum(axis=1) / target_mask_val.sum(axis=1)\n",
    "        \n",
    "        mean_batch_pred = torch.repeat_interleave(mean_seq_val, n_cell_types, dim=0)\n",
    "        mean_batch_pred = mean_batch_pred.view(-1, n_features)\n",
    "        batch_gt = targets.view(-1, n_features)\n",
    "        #batch_mask = (target_mask_val).view(-1, n_features).astype(np.bool)\n",
    "        batch_mask = (target_mask_val).view(-1, n_features)\n",
    "        \n",
    "        # mask of samples to save for evaluation\n",
    "        save_mask = np.random.choice(mean_batch_pred.shape[0], mean_batch_pred.shape[0] // 16, replace=False)\n",
    "        \n",
    "        gts.append(batch_gt.data.numpy()[save_mask])\n",
    "        mean_preds.append(mean_batch_pred.data.numpy()[save_mask])\n",
    "        # masks for metric computation\n",
    "        masks.append(batch_mask.data.numpy()[save_mask])\n",
    "        del batch\n",
    "\n",
    "    gts = expand_dims(np.concatenate(gts))\n",
    "    np.save(f'results/gts_val_fold_{fold}.npy', gts)\n",
    "    \n",
    "    mean_preds = expand_dims(np.concatenate(mean_preds))\n",
    "    np.save(f'results/mean_preds_val_fold_{fold}.npy', mean_preds)\n",
    "    \n",
    "    masks = expand_dims(np.concatenate(masks))\n",
    "    np.save(f'results/masks_val_fold_{fold}.npy', masks)\n",
    "\n",
    "    map_val, ap_val = compute_score(\n",
    "        mean_preds, \n",
    "        gts, \n",
    "        average_precision_score, \n",
    "        target_mask=masks#.astype(np.bool)\n",
    "        )\n",
    "\n",
    "    del gts\n",
    "    del mean_preds\n",
    "    del masks\n",
    "    gc.colect()\n",
    "\n",
    "    print(fold, map_val, ap_val)\n",
    "\n",
    "    np.save(f'results/mean_pos_val_ap_fold_{fold}.npy', ap_val)\n",
    "    np.save(f'results/mean_pos_val_map_fold_{fold}.npy', map_val)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/36889 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-80d65ec198e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mmasked_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtarget_mask_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mmean_seq_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtarget_mask_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "gts = np.load('results/gts_val_fold_0.npy')\n",
    "mean_preds = np.load('results/mean_preds_val_fold_0.npy')\n",
    "masks = np.load('results/masks_val_fold_0.npy')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "gts[:10]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "mean_preds[:10]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.24603175],\n",
       "       [0.9126984 ],\n",
       "       [0.        ],\n",
       "       [0.06349207],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.00793651]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "masks[:10]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "map_val, ap_val = compute_score(\n",
    "    mean_preds, \n",
    "    gts, \n",
    "    average_precision_score, \n",
    "    target_mask=masks#.astype(np.bool)\n",
    "    )\n",
    "\n",
    "# np.save('mean_pos_val_ap_top4.npy', ap_val)\n",
    "# np.save('mean_pos_val_map_top4.npy', map_val)\n",
    "\n",
    "map_val, ap_val"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.56052681592646, array([0.56052682]))"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "gts_1 = np.load('results/gts_val_fold_1.npy')\n",
    "mean_preds_1 = np.load('results/mean_preds_val_fold_1.npy')\n",
    "masks_1 = np.load('results/masks_val_fold_1.npy')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "map_val_1, ap_val_1 = compute_score(\n",
    "    mean_preds_1, \n",
    "    gts_1, \n",
    "    average_precision_score, \n",
    "    target_mask=masks_1#.astype(np.bool)\n",
    "    )\n",
    "\n",
    "map_val_1, ap_val_1"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.545688774106069, array([0.54568877]))"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "base_scores_tr = []\n",
    "base_scores_val = []\n",
    "\n",
    "for fold, (tr_idx, val_idx) in enumerate(k_fold.split(genome_intervals_arr)):\n",
    "    print(fold)\n",
    "\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        sequence_batch, _, targets, target_mask = batch\n",
    "        print(targets)\n",
    "        print(targets.shape)\n",
    "        print(target_mask.sum())\n",
    "        \n",
    "        # make train mask\n",
    "        target_mask_tr = target_mask.clone()\n",
    "        target_mask_tr[:, ct_mask_range[fold][0]: ct_mask_range[fold][-1]] = False\n",
    "        print(target_mask_tr.sum())\n",
    "\n",
    "        targets *= target_mask_tr\n",
    "        print(targets)\n",
    "\n",
    "        mean_seq_val = (targets).sum(axis=1) / target_mask_tr.sum(axis=1)\n",
    "        print(mean_seq_val)\n",
    "        mean_seq_batch = torch.repeat_interleave(mean_seq_val.unsqueeze(1), configs['model']['class_args']['n_cell_types'], dim=1)    \n",
    "        print(mean_seq_batch.shape)\n",
    "        \n",
    "        # base_score = average_precision_score(mean_seq_batch, targets)\n",
    "        # print('base_score', base_score)\n",
    "        # base_scores_val.append(base_score)    \n",
    "\n",
    "        1/0\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "tensor([[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]])\n",
      "torch.Size([2, 631, 1])\n",
      "tensor(1262)\n",
      "tensor(1136)\n",
      "tensor([[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]])\n",
      "tensor([[0.0018],\n",
      "        [0.1884]])\n",
      "torch.Size([2, 631, 1])\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-266592d5671d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# base_scores_val.append(base_score)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "base_score = average_precision_score(mean_seq_batch.numpy(), targets.numpy())\n",
    "base_score"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "unknown format is not supported",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-977c3cfffb0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbase_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage_precision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_seq_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbase_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/genv/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/genv/lib/python3.6/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36maverage_precision_score\u001b[0;34m(y_true, y_score, average, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    223\u001b[0m                                 pos_label=pos_label)\n\u001b[1;32m    224\u001b[0m     return _average_binary_score(average_precision, y_true, y_score,\n\u001b[0;32m--> 225\u001b[0;31m                                  average, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/genv/lib/python3.6/site-packages/sklearn/metrics/_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: unknown format is not supported"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "mean_seq_batch.numpy()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[[0.00176056],\n",
       "        [0.00176056],\n",
       "        [0.00176056],\n",
       "        ...,\n",
       "        [0.00176056],\n",
       "        [0.00176056],\n",
       "        [0.00176056]],\n",
       "\n",
       "       [[0.18838029],\n",
       "        [0.18838029],\n",
       "        [0.18838029],\n",
       "        ...,\n",
       "        [0.18838029],\n",
       "        [0.18838029],\n",
       "        [0.18838029]]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "targets"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]])"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "mean_seq_batch"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[0.0018],\n",
       "         [0.0018],\n",
       "         [0.0018],\n",
       "         ...,\n",
       "         [0.0018],\n",
       "         [0.0018],\n",
       "         [0.0018]],\n",
       "\n",
       "        [[0.1884],\n",
       "         [0.1884],\n",
       "         [0.1884],\n",
       "         ...,\n",
       "         [0.1884],\n",
       "         [0.1884],\n",
       "         [0.1884]]])"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "base_score = average_precision_score(mean_seq_batch, targets)\n",
    "print('base_score', base_score)\n",
    "base_scores_val.append(base_score)    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# K-fold\n",
    "## Stratified K-fold"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "genome_intervals = []\n",
    "with open(cfg.datamodule.sampling_intervals_path) as f:\n",
    "    for line in f:\n",
    "        chrom, start, end = interval_from_line(line)\n",
    "        genome_intervals.append((chrom, start, end))\n",
    "\n",
    "print(len(genome_intervals))\n",
    "\n",
    "genome_intervals_arr = np.asarray(genome_intervals, dtype='U10,i8,i8')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1377454\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "genome_intervals_arr[:10]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([('chr1',  10500,  10680), ('chr1', 713420, 714955),\n",
       "       ('chr1', 752395, 752905), ('chr1', 753270, 753580),\n",
       "       ('chr1', 754045, 754605), ('chr1', 762595, 763055),\n",
       "       ('chr1', 766170, 766430), ('chr1', 766595, 767180),\n",
       "       ('chr1', 770945, 771205), ('chr1', 773070, 773355)],\n",
       "      dtype=[('f0', '<U10'), ('f1', '<i8'), ('f2', '<i8')])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "train_transforms = transforms.Compose([\n",
    "            PermuteSequenceChannels(), \n",
    "            RandomReverseStrand(p=0.5)\n",
    "        ])\n",
    "        \n",
    "val_transform = PermuteSequenceChannels()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss(reduction='sum')\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr = 0.0001, weight_decay = 1e-6)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "train_loader.batch_size"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "tr_idx_list = []\n",
    "val_idx_list = []\n",
    "\n",
    "for fold, (tr_idx, val_idx) in enumerate(k_fold.split(genome_intervals_arr)):\n",
    "    # print(fold)\n",
    "    tr_idx_list.append(tr_idx)\n",
    "    val_idx_list.append(val_idx)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "val_idx_list[:3]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[array([     0,      1,      2, ..., 137743, 137744, 137745]),\n",
       " array([137746, 137747, 137748, ..., 275489, 275490, 275491]),\n",
       " array([275492, 275493, 275494, ..., 413235, 413236, 413237])]"
      ]
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "len(tr_idx_list[9])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1239709"
      ]
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "# ct_mask_idx = np.array_split(range(cfg.model.params.n_cell_types), 10)\n",
    "# genome_intervals_arr = np.asarray(genome_intervals, dtype='U10,i8,i8')\n",
    "model_scores_tr = []\n",
    "base_scores_tr = []\n",
    "model_scores_val = []\n",
    "base_scores_val = []\n",
    "\n",
    "\n",
    "model = DeepCT(m_cfg)\n",
    "model.train()\n",
    "\n",
    "for fold, (tr_idx, val_idx) in enumerate(k_fold.split(genome_intervals_arr)):\n",
    "    print(fold)\n",
    "\n",
    "    # train/val split\n",
    "    tr_intervals = genome_intervals_arr[tr_idx].tolist()\n",
    "    val_intervals = genome_intervals_arr[val_idx].tolist()\n",
    "\n",
    "    train_dataset = load_obj(cfg.datamodule.class_name)(\n",
    "            cfg=cfg,\n",
    "            distinct_features=distinct_features,\n",
    "            target_features=target_features,\n",
    "            intervals=tr_intervals,\n",
    "            transform=train_transforms,\n",
    "        )\n",
    "    val_dataset = load_obj(cfg.datamodule.class_name)(\n",
    "            cfg=cfg,\n",
    "            distinct_features=distinct_features,\n",
    "            target_features=target_features,\n",
    "            intervals=val_intervals,\n",
    "            transform=train_transforms,\n",
    "        )\n",
    "    \n",
    "    train_loader = get_loader(train_dataset, batch_size=2, num_workers=1, shuffle=666)\n",
    "    val_loader = get_loader(val_dataset, batch_size=2, num_workers=1, shuffle=666)\n",
    "\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        sequence_batch, _, targets, target_mask = batch\n",
    "        \n",
    "        # make train mask\n",
    "        target_mask_tr = target_mask.clone()\n",
    "        target_mask_tr[:, ct_mask_idx[fold][0]: ct_mask_idx[fold][-1]] = False\n",
    "        \n",
    "        logits = model(sequence_batch)\n",
    "        # predictions = torch.sigmoid(logits)*target_mask_tr#.view(train_loader.batch_size, cfg.model.params.n_cell_types, 1)\n",
    "\n",
    "        criterion.weight = target_mask_tr\n",
    "        loss = criterion(predictions, targets.float())\n",
    "        loss = loss / criterion.weight.sum()\n",
    "        print(\"train loss:\", loss.item())\n",
    "\n",
    "        \n",
    "        # model_score = avg_pr(predictions[target_mask_tr], targets[target_mask_tr])\n",
    "        # model_scores_tr.append(model_score)\n",
    "        # base_score = avg_pr(mean_seq_batch[target_mask_tr], targets[target_mask_tr])\n",
    "\n",
    "        # optimizer.zero_grad()\n",
    "        # loss.backward(retain_graph=True)\n",
    "        # optimizer.step()\n",
    "\n",
    "        if i >= 2:\n",
    "            break\n",
    "\n",
    "    for batch in val_loader:\n",
    "        sequence_batch, _, targets, target_mask = batch\n",
    "\n",
    "        # val mask\n",
    "        target_mask_val = ~target_mask_tr\n",
    "\n",
    "        targets = targets * target_mask_val\n",
    "        \n",
    "        # compute baseline\n",
    "        mean_seq_val = (targets * target_mask_val).sum(axis=1) / target_mask_val.sum(axis=1)\n",
    "        print('mean_seq_val', mean_seq_val)\n",
    "        mean_seq_batch = torch.repeat_interleave(mean_seq_val.unsqueeze(1), cfg.model.params.n_cell_types, dim=1)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            logits = model(sequence_batch)\n",
    "            predictions = torch.sigmoid(logits)#[target_mask_val].view(val_loader.batch_size, cfg.model.params.n_cell_types, 1)\n",
    "            predictions = predictions*target_mask_val\n",
    "\n",
    "            criterion.weight = target_mask_val\n",
    "            loss = criterion(predictions, targets.float())\n",
    "            loss = loss / criterion.weight.sum()\n",
    "\n",
    "\n",
    "            model_score_val = avg_pr(predictions, targets)\n",
    "            model_scores_val.append(model_score_val)\n",
    "\n",
    "            base_score = avg_pr(mean_seq_batch, targets)\n",
    "            print('base_score', base_score)\n",
    "            base_scores_val.append(base_score)\n",
    "\n",
    "        print(\"val loss:\", loss.item())\n",
    "\n",
    "        if i >= 2:\n",
    "            break\n",
    "\n",
    "    break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "train loss: 0.9745064377784729\n",
      "train loss: 0.9696027636528015\n",
      "train loss: 0.9762895703315735\n",
      "mean_seq_val tensor([[0.0159],\n",
      "        [0.0000]])\n",
      "base_score tensor(0.0016)\n",
      "val loss: 0.9698627591133118\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# проверить подсчет baseline\n",
    "# подумать как сохранять модели\n",
    "# впилить это всё в DeepCT"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "target_mask_val.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([2, 631, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "mean_seq_batch = torch.repeat_interleave(mean_seq_val.unsqueeze(1), cfg.model.params.n_cell_types, dim=1)\n",
    "mean_seq_batch.shape\n",
    "# mean_seq_batch = mean_seq_batch[target_mask_val]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([2, 631, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "mean_seq_batch = mean_seq_batch*target_mask_val\n",
    "mean_seq_batch.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([2, 631, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "target_mask_val.sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'class_name': 'pipeline.models.deepct_model_multi_ct.DeepCT', 'params': {'sequence_length': 1000, 'n_cell_types': 631, 'sequence_embedding_length': 256, 'cell_type_embedding_length': 32, 'final_embedding_length': 256, 'n_genomic_features': 1, 'conv_kernel_size': 8, 'pool_kernel_size': 4}}"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "dataset_class = getattr(module, dataset_info[\"class\"])\n",
    "\n",
    "load_train_val = False\n",
    "load_test = False\n",
    "\n",
    "if \"dataset\" in configs:\n",
    "    dataset_info = configs[\"dataset\"]\n",
    "    genome_intervals = []\n",
    "    # genome_intervals = np.array([])\n",
    "    with open(dataset_info[\"sampling_intervals_path\"]) as f:\n",
    "        for line in f:\n",
    "            chrom, start, end = line.rstrip().split(\"\\t\")[:3]\n",
    "            start = int(start)\n",
    "            end = int(end)\n",
    "            genome_intervals.append((chrom, start, end))\n",
    "            # genome_intervals = np.append(genome_intervals, (chrom, start, end))\n",
    "            \n",
    "    with open(dataset_info[\"distinct_features_path\"]) as f:\n",
    "        distinct_features = list(map(lambda x: x.rstrip(), f.readlines()))\n",
    "\n",
    "    with open(dataset_info[\"target_features_path\"]) as f:\n",
    "        target_features = list(map(lambda x: x.rstrip(), f.readlines()))\n",
    "\n",
    "dataset_info[\"dataset_args\"][\"target_features\"] = target_features\n",
    "dataset_info[\"dataset_args\"][\"distinct_features\"] = distinct_features\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "genome_intervals[:5], len(genome_intervals)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "([('chr1', 10500, 10680),\n",
       "  ('chr1', 713420, 714955),\n",
       "  ('chr1', 752395, 752905),\n",
       "  ('chr1', 753270, 753580),\n",
       "  ('chr1', 754045, 754605)],\n",
       " 1377454)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "distinct_features[:5], len(distinct_features)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(['8988T|DNase-seq|None',\n",
       "  'A172|DNase-seq|None',\n",
       "  'A549_treated_with_100_nM_dexamethasone_for_10_hours|DNase-seq|None',\n",
       "  'A549_treated_with_100_nM_dexamethasone_for_12_hours|DNase-seq|None',\n",
       "  'A549_treated_with_100_nM_dexamethasone_for_1_hour|DNase-seq|None'],\n",
       " 631)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# distinct_features == tracks (feature + cell_type)\n",
    "data_config = dataset_info[\"dataset_args\"].copy()\n",
    "data_config[\"intervals\"] = genome_intervals"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "fold = KFold(10, shuffle=False)\n",
    "# fold = KFold(10, shuffle=True, random_state=666)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "data_config = dataset_info[\"dataset_args\"].copy()\n",
    "data_config[\"intervals\"] = genome_intervals\n",
    "\n",
    "full_dataset = dataset_class(**data_config)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# train_dataset.__getitem__(0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# genome_intervals#_arr"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# np.asarray(genome_intervals, dtype='U10,i8,i8')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# 1 - loc folds\n",
    "\n",
    "batch_size = dataset_info['loader_args']['batch_size']\n",
    "train_transform = instantiate(dataset_info[\"train_transform\"])\n",
    "val_transform = PermuteSequenceChannels()\n",
    "\n",
    "sampler_class = getattr(module, dataset_info[\"sampler_class\"])\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(configs[\"random_seed\"])\n",
    "\n",
    "\n",
    "genome_intervals_arr = np.asarray(genome_intervals, dtype='U10,i8,i8')\n",
    "\n",
    "for f, (tr_idx, val_idx) in enumerate(fold.split(genome_intervals_arr)):\n",
    "    tr_intervals = genome_intervals_arr[tr_idx].tolist()\n",
    "    val_intervals = genome_intervals_arr[val_idx].tolist()\n",
    "\n",
    "    train_config = dataset_info[\"dataset_args\"].copy()\n",
    "    train_config[\"intervals\"] = tr_intervals\n",
    "    train_config[\"transform\"] = train_transform\n",
    "\n",
    "    val_config = dataset_info[\"dataset_args\"].copy()\n",
    "    val_config[\"intervals\"] = val_intervals\n",
    "    val_config[\"transform\"] = val_transform\n",
    "\n",
    "    train_dataset = dataset_class(**train_config)\n",
    "    val_dataset = dataset_class(**val_config)\n",
    "\n",
    "    train_sampler = sampler_class(\n",
    "        train_dataset, replacement=False, generator=gen)\n",
    "\n",
    "    val_sampler = sampler_class(\n",
    "        val_dataset, replacement=False, generator=gen)\n",
    "\n",
    "\n",
    "    # train_dataset = GenSubset(full_dataset, tr_idx, transform=train_transform)\n",
    "    # val_dataset = GenSubset(full_dataset, val_idx, transform=val_transform)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                            batch_size=batch_size,\n",
    "                                            num_workers=dataset_info[\"loader_args\"][\"num_workers\"],\n",
    "                                            worker_init_fn=module.encode_worker_init_fn,\n",
    "                                            sampler=train_sampler,\n",
    "                                        )\n",
    "    val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                            batch_size=batch_size,\n",
    "                                            num_workers=dataset_info[\"loader_args\"][\"num_workers\"],\n",
    "                                            worker_init_fn=module.encode_worker_init_fn,\n",
    "                                            sampler=val_sampler,\n",
    "                                        )\n",
    "\n",
    "    print(len(train_loader), len(val_loader))\n",
    "\n",
    "\n",
    "\n",
    "    1/0"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1032815 124804\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-1704bfe5effa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "for f, (tr_idx, val_idx) in enumerate(fold.split(genome_intervals_arr)):\n",
    "    tr_intervals = genome_intervals_arr[tr_idx].tolist()\n",
    "    val_intervals = genome_intervals_arr[val_idx].tolist()\n",
    "\n",
    "    print(f, val_idx)\n",
    "    # 1/0"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 [     0      1      2 ... 137743 137744 137745]\n",
      "1 [137746 137747 137748 ... 275489 275490 275491]\n",
      "2 [275492 275493 275494 ... 413235 413236 413237]\n",
      "3 [413238 413239 413240 ... 550981 550982 550983]\n",
      "4 [550984 550985 550986 ... 688726 688727 688728]\n",
      "5 [688729 688730 688731 ... 826471 826472 826473]\n",
      "6 [826474 826475 826476 ... 964216 964217 964218]\n",
      "7 [ 964219  964220  964221 ... 1101961 1101962 1101963]\n",
      "8 [1101964 1101965 1101966 ... 1239706 1239707 1239708]\n",
      "9 [1239709 1239710 1239711 ... 1377451 1377452 1377453]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "from pipeline.models.deepct_model_multi_ct import DeepCT\n",
    "\n",
    "model = DeepCT(**configs['model']['class_args'])\n",
    "model.train()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DeepCT(\n",
       "  (conv_net): Sequential(\n",
       "    (0): Conv1d(4, 320, kernel_size=(8,), stride=(1,))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv1d(320, 320, kernel_size=(8,), stride=(1,))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Conv1d(320, 480, kernel_size=(8,), stride=(1,))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv1d(480, 480, kernel_size=(8,), stride=(1,))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): BatchNorm1d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): Dropout(p=0.2, inplace=False)\n",
       "    (13): Conv1d(480, 960, kernel_size=(8,), stride=(1,))\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): Conv1d(960, 960, kernel_size=(8,), stride=(1,))\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): BatchNorm1d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (18): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (sequence_net): Sequential(\n",
       "    (0): Linear(in_features=42240, out_features=256, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (cell_type_net): Sequential(\n",
       "    (0): Linear(in_features=631, out_features=32, bias=True)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=288, out_features=256, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "# retrieved_seq, cell_type, target, target_mask\n",
    "sequence_batch = batch[0]#.to(device)\n",
    "cell_type_batch = batch[1]#.to(device)\n",
    "targets = batch[2]#.to(device)\n",
    "target_mask = batch[3]#.to(device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "targets.shape, target_mask.shape, cell_type_batch.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([10, 631, 1]), torch.Size([10, 631, 1]), torch.Size([10]))"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "target_mask.shape[1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "631"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss(reduction='sum')\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr = 0.0001, weight_decay = 1e-6)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "criterion.reduction"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'sum'"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "optimizer"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.0001\n",
       "    weight_decay: 1e-06\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "model = DeepCT(**configs['model']['class_args'])\n",
    "model.train()\n",
    "\n",
    "\n",
    "batch_size = dataset_info['loader_args']['batch_size']\n",
    "train_transform = instantiate(dataset_info[\"train_transform\"])\n",
    "val_transform = PermuteSequenceChannels()\n",
    "\n",
    "sampler_class = getattr(module, dataset_info[\"sampler_class\"])\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(configs[\"random_seed\"])\n",
    "\n",
    "ct_mask_idx = np.array_split(range(configs['model']['class_args']['n_cell_types']), 10)\n",
    "\n",
    "genome_intervals_arr = np.asarray(genome_intervals, dtype='U10,i8,i8')\n",
    "\n",
    "for f, (tr_idx, val_idx) in enumerate(fold.split(genome_intervals_arr)):\n",
    "    tr_intervals = genome_intervals_arr[tr_idx].tolist()\n",
    "    val_intervals = genome_intervals_arr[val_idx].tolist()\n",
    "\n",
    "    train_config = dataset_info[\"dataset_args\"].copy()\n",
    "    train_config[\"intervals\"] = tr_intervals\n",
    "    train_config[\"transform\"] = train_transform\n",
    "\n",
    "    val_config = dataset_info[\"dataset_args\"].copy()\n",
    "    val_config[\"intervals\"] = val_intervals\n",
    "    val_config[\"transform\"] = val_transform\n",
    "\n",
    "    train_dataset = dataset_class(**train_config)\n",
    "    val_dataset = dataset_class(**val_config)\n",
    "\n",
    "    train_sampler = sampler_class(\n",
    "        train_dataset, replacement=False, generator=gen)\n",
    "\n",
    "    val_sampler = sampler_class(\n",
    "        val_dataset, replacement=False, generator=gen)\n",
    "\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                            batch_size=batch_size,\n",
    "                                            num_workers=dataset_info[\"loader_args\"][\"num_workers\"],\n",
    "                                            worker_init_fn=module.encode_worker_init_fn,\n",
    "                                            sampler=train_sampler,\n",
    "                                        )\n",
    "    val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                            batch_size=batch_size,\n",
    "                                            num_workers=dataset_info[\"loader_args\"][\"num_workers\"],\n",
    "                                            worker_init_fn=module.encode_worker_init_fn,\n",
    "                                            sampler=val_sampler,\n",
    "                                        )\n",
    "\n",
    "    for batch in train_loader:\n",
    "        sequence_batch = batch[0]#.to(device)\n",
    "        cell_type_batch = batch[1]#.to(device)\n",
    "        targets = batch[2]#.to(device)\n",
    "        target_mask = batch[3]#.to(device)\n",
    "        \n",
    "        target_mask_tr = target_mask.clone()\n",
    "        target_mask_tr[:, ct_mask_idx[f][0]: ct_mask_idx[f][-1]] = False\n",
    "        \n",
    "        outputs = model(sequence_batch, cell_type_batch)\n",
    "\n",
    "        criterion.weight = target_mask_tr\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss = loss / criterion.weight.sum()\n",
    "        print(\"train loss:\", loss.item())\n",
    "\n",
    "        predictions = torch.sigmoid(outputs)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        break\n",
    "\n",
    "    break\n",
    "\n",
    "    # for batch in val_loader:\n",
    "    #     sequence_batch = batch[0]#.to(device)\n",
    "    #     cell_type_batch = batch[1]#.to(device)\n",
    "    #     targets = batch[2]#.to(device)\n",
    "    #     target_mask = batch[3]#.to(device)\n",
    "\n",
    "    #     # val mask\n",
    "    #     target_mask_val = ~target_mask\n",
    "\n",
    "    #     model.eval()\n",
    "    #     with torch.no_grad():\n",
    "    #         outputs = model(sequence_batch, cell_type_batch)\n",
    "\n",
    "    #         criterion.weight = target_mask_val\n",
    "    #         loss = criterion(outputs, targets)\n",
    "    #         loss = loss / criterion.weight.sum()\n",
    "\n",
    "    #         val_predictions = torch.sigmoid(outputs)\n",
    "\n",
    "\n",
    "    #     print(\"val loss:\", loss.item())\n",
    "\n",
    "\n",
    "        # break\n",
    "\n",
    "    # 1/0\n",
    "\n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train loss: 0.00011682936747092754\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "# ct_mask_idx = np.array_split(range(configs['model']['class_args']['n_cell_types']), 10)\n",
    "# [len(c) for c in ct_mask_idx]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[64, 63, 63, 63, 63, 63, 63, 63, 63, 63]"
      ]
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "criterion.weight[1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]])"
      ]
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "criterion.weight[1].sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(568)"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "for batch in val_loader:\n",
    "    sequence_batch = batch[0]#.to(device)\n",
    "    cell_type_batch = batch[1]#.to(device)\n",
    "    targets = batch[2]#.to(device)\n",
    "    # target_mask = batch[3]#.to(device)\n",
    "\n",
    "    # val mask\n",
    "    target_mask_val = ~target_mask_tr\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(sequence_batch, cell_type_batch)\n",
    "\n",
    "        criterion.weight = target_mask_val\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss = loss / criterion.weight.sum()\n",
    "\n",
    "        val_predictions = torch.sigmoid(outputs)\n",
    "\n",
    "\n",
    "    print(\"val loss:\", loss.item())\n",
    "    break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val loss: 0.0001089841389330104\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "criterion.weight[1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False]])"
      ]
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "criterion.weight[1].sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(63)"
      ]
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "source": [
    "sequence_batch.shape, cell_type_batch.shape, targets.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([10, 4, 1000]), torch.Size([10]), torch.Size([10, 631, 1]))"
      ]
     },
     "metadata": {},
     "execution_count": 141
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "source": [
    "outputs = model(sequence_batch, cell_type_batch)\n",
    "outputs.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([10, 631, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 144
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "source": [
    "criterion.weight = target_mask_tr\n",
    "loss = criterion(outputs, targets)\n",
    "loss = loss / criterion.weight.sum()\n",
    "loss.item()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(0.0001, grad_fn=<DivBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 145
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "source": [
    "predictions = torch.sigmoid(outputs)\n",
    "predictions.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([10, 631, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 147
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "source": [
    "model.eval()\n",
    "\n",
    "for val_batch in val_loader:\n",
    "    val_sequence_batch = val_batch[0]#.to(device)\n",
    "    val_cell_type_batch = val_batch[1]#.to(device)\n",
    "    val_targets = val_batch[2]#.to(device)\n",
    "    val_target_mask = val_batch[3]#.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(val_sequence_batch, val_cell_type_batch)\n",
    "\n",
    "        criterion.weight = target_mask_val\n",
    "        loss = criterion(outputs, val_targets)\n",
    "        loss = loss / criterion.weight.sum()\n",
    "\n",
    "        val_predictions = torch.sigmoid(outputs)\n",
    "\n",
    "        break\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "source": [
    "loss.item()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.00010881867638090625"
      ]
     },
     "metadata": {},
     "execution_count": 150
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "source": [
    "val_predictions#.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[0.4966],\n",
       "         [0.4966],\n",
       "         [0.4966],\n",
       "         ...,\n",
       "         [0.4966],\n",
       "         [0.4966],\n",
       "         [0.4966]],\n",
       "\n",
       "        [[0.4966],\n",
       "         [0.4966],\n",
       "         [0.4966],\n",
       "         ...,\n",
       "         [0.4966],\n",
       "         [0.4966],\n",
       "         [0.4966]],\n",
       "\n",
       "        [[0.4966],\n",
       "         [0.4966],\n",
       "         [0.4966],\n",
       "         ...,\n",
       "         [0.4966],\n",
       "         [0.4966],\n",
       "         [0.4966]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.4966],\n",
       "         [0.4966],\n",
       "         [0.4966],\n",
       "         ...,\n",
       "         [0.4966],\n",
       "         [0.4966],\n",
       "         [0.4966]],\n",
       "\n",
       "        [[0.4966],\n",
       "         [0.4966],\n",
       "         [0.4966],\n",
       "         ...,\n",
       "         [0.4966],\n",
       "         [0.4966],\n",
       "         [0.4966]],\n",
       "\n",
       "        [[0.4966],\n",
       "         [0.4966],\n",
       "         [0.4966],\n",
       "         ...,\n",
       "         [0.4966],\n",
       "         [0.4966],\n",
       "         [0.4966]]])"
      ]
     },
     "metadata": {},
     "execution_count": 155
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit ('genv': venv)"
  },
  "interpreter": {
   "hash": "7bed6a5b8f0827f7d7f30ba9d7b2c61fcd2f223009d9afc95ff59e669a7c4ade"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}