{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "import yaml\n",
    "import os\n",
    "import sys\n",
    "# sys.path.append('../../')\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from omegaconf import OmegaConf\n",
    "# import torchmetrics\n",
    "# import torch\n",
    "# from torch import nn\n",
    "from selene_sdk.utils import load_path, parse_configs_and_run\n",
    "from selene_sdk.utils.config_utils import module_from_dir, module_from_file\n",
    "from selene_sdk.utils.config import instantiate\n",
    "from src.dataset import EncodeDataset, LargeRandomSampler, encode_worker_init_fn\n",
    "from src.transforms import *\n",
    "from src.utils import interval_from_line\n",
    "# from torchvision import transforms\n",
    "# from torchmetrics import BinnedAveragePrecision, AveragePrecision, Accuracy\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import copy\n",
    "from src.utils import expand_dims\n",
    "import gc\n",
    "gc.enable()\n",
    "\n",
    "from src.metrics import jaccard_score, threshold_wrapper\n",
    "from sklearn.metrics import average_precision_score\n",
    "from selene_sdk.utils.performance_metrics import compute_score\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[autoreload of src.dataset failed: Traceback (most recent call last):\n",
      "  File \"/home/thurs/genv/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/thurs/genv/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 410, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/home/thurs/genv/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/thurs/genv/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 302, in update_class\n",
      "    if update_generic(old_obj, new_obj): continue\n",
      "  File \"/home/thurs/genv/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/thurs/genv/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 302, in update_class\n",
      "    if update_generic(old_obj, new_obj): continue\n",
      "  File \"/home/thurs/genv/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/thurs/genv/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 302, in update_class\n",
      "    if update_generic(old_obj, new_obj): continue\n",
      "  File \"/home/thurs/genv/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/thurs/genv/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 302, in update_class\n",
      "    if update_generic(old_obj, new_obj): continue\n",
      "RecursionError: maximum recursion depth exceeded\n",
      "]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "path = 'model_configs/biox_dnase_multi_ct_crossval.yaml'\n",
    "configs = load_path(path, instantiate=False)\n",
    "# configs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "configs['dataset']['loader_args']['batch_size'] = 64"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "configs['dataset']['loader_args']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'batch_size': 64, 'num_workers': 16}"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from sklearn.model_selection import KFold, GroupKFold, StratifiedKFold\n",
    "\n",
    "n_folds = 5\n",
    "k_fold = KFold(n_folds, shuffle=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "ct_mask_range = np.array_split(range(configs['model']['class_args']['n_cell_types']), n_folds)\n",
    "len(ct_mask_range)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "from selene_sdk.targets import GenomicFeatures\n",
    "\n",
    "\n",
    "def _construct_target(target_path, distinct_features, feature_thresholds=0.5):\n",
    "\n",
    "    return GenomicFeatures(\n",
    "        target_path,\n",
    "        distinct_features,\n",
    "        feature_thresholds=feature_thresholds,\n",
    "    )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "import random\n",
    "from selene_sdk.utils.config_utils import get_fold_idx\n",
    "\n",
    "\n",
    "def get_loaders(configs, output_dir=None, load_test=False):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    if \"sampler\" in configs:\n",
    "        sampler_info = configs[\"sampler\"]\n",
    "        if output_dir is not None:\n",
    "            sampler_info.bind(output_dir=output_dir)\n",
    "        sampler = instantiate(sampler_info)\n",
    "        return sampler\n",
    "    if \"dataset\" in configs:\n",
    "        dataset_info = configs[\"dataset\"]\n",
    "\n",
    "        # all intervals\n",
    "        genome_intervals = []\n",
    "        with open(dataset_info[\"sampling_intervals_path\"])  as f:\n",
    "            for line in f:\n",
    "                chrom, start, end = interval_from_line(line)\n",
    "                genome_intervals.append((chrom, start, end))\n",
    "\n",
    "        # bedug\n",
    "        # genome_intervals = random.sample(genome_intervals, k=20)\n",
    "        # print(\"DEBUG MODE ON:\", len(genome_intervals))\n",
    "\n",
    "        with open(dataset_info[\"distinct_features_path\"]) as f:\n",
    "            distinct_features = list(map(lambda x: x.rstrip(), f.readlines()))\n",
    "\n",
    "        with open(dataset_info[\"target_features_path\"]) as f:\n",
    "            target_features = list(map(lambda x: x.rstrip(), f.readlines()))\n",
    "\n",
    "        module = None\n",
    "        if os.path.isdir(dataset_info[\"path\"]):\n",
    "            module = module_from_dir(dataset_info[\"path\"])\n",
    "        else:\n",
    "            module = module_from_file(dataset_info[\"path\"])\n",
    "\n",
    "        dataset_class = getattr(module, dataset_info[\"class\"])\n",
    "        dataset_info[\"dataset_args\"][\"target_features\"] = target_features\n",
    "        dataset_info[\"dataset_args\"][\"distinct_features\"] = distinct_features\n",
    "\n",
    "        # load train dataset and loader\n",
    "        data_config = dataset_info[\"dataset_args\"].copy()\n",
    "        data_config[\"intervals\"] = genome_intervals\n",
    "\n",
    "        genome_intervals_arr, tr_idx_list, val_idx_list = get_fold_idx(\n",
    "            genome_intervals,  \n",
    "            configs,\n",
    "            )\n",
    "\n",
    "        # train/val split\n",
    "        tr_idx = tr_idx_list[dataset_info[\"dataset_args\"][\"fold\"]]\n",
    "        val_idx = val_idx_list[dataset_info[\"dataset_args\"][\"fold\"]]\n",
    "        train_intervals = genome_intervals_arr[tr_idx].tolist()\n",
    "        val_intervals = genome_intervals_arr[val_idx].tolist()\n",
    "\n",
    "        train_config = dataset_info[\"dataset_args\"].copy()\n",
    "        del train_config['fold']\n",
    "        del train_config['n_folds']\n",
    "        train_config[\"intervals\"] = train_intervals\n",
    "        if \"train_transform\" in dataset_info:\n",
    "            # load transforms\n",
    "            train_transform = instantiate(dataset_info[\"train_transform\"])\n",
    "            train_config[\"transform\"] = train_transform\n",
    "        train_dataset = dataset_class(**train_config)\n",
    "\n",
    "        sampler_class = getattr(module, dataset_info[\"sampler_class\"])\n",
    "        gen = torch.Generator()\n",
    "        gen.manual_seed(configs[\"random_seed\"])\n",
    "        train_sampler = sampler_class(\n",
    "            train_dataset, replacement=False, generator=gen\n",
    "        )\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=dataset_info[\"loader_args\"][\"batch_size\"],\n",
    "            num_workers=dataset_info[\"loader_args\"][\"num_workers\"],\n",
    "            worker_init_fn=module.encode_worker_init_fn,\n",
    "            sampler=train_sampler,\n",
    "        )\n",
    "\n",
    "        # load validation dataset and loader\n",
    "        val_config = dataset_info[\"dataset_args\"].copy()\n",
    "        del val_config['fold']\n",
    "        del val_config['n_folds']\n",
    "        val_config[\"intervals\"] = val_intervals\n",
    "        if \"val_transform\" in dataset_info:\n",
    "            # load transforms\n",
    "            val_transform = instantiate(dataset_info[\"val_transform\"])\n",
    "            val_config[\"transform\"] = val_transform\n",
    "        val_dataset = dataset_class(**val_config)\n",
    "\n",
    "        val_loader = torch.utils.data.DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=dataset_info[\"loader_args\"][\"batch_size\"],\n",
    "            num_workers=dataset_info[\"loader_args\"][\"num_workers\"],\n",
    "            worker_init_fn=module.encode_worker_init_fn,\n",
    "        )\n",
    "\n",
    "        out = {\n",
    "            'genome_intervals': genome_intervals_arr, \n",
    "            'train_idx': tr_idx_list,\n",
    "            'val_idx': val_idx_list,\n",
    "            'train_loader': train_loader, \n",
    "            'val_loader': val_loader,\n",
    "        }\n",
    "\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# from selene_sdk.utils.config_utils import get_loaders\n",
    "\n",
    "out = get_loaders(configs)\n",
    "genome_intervals_arr = out['genome_intervals'] \n",
    "tr_idx_list = out['train_idx']\n",
    "val_idx_list = out['val_idx']\n",
    "train_loader = out['train_loader']\n",
    "val_loader = out['val_loader']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "len(train_loader), len(val_loader)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(143990, 36889)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "batch_size = val_loader.batch_size\n",
    "print(batch_size)\n",
    "n_cell_types = configs['model']['class_args']['n_cell_types']\n",
    "# boix_target_features = val_loader.target_features\n",
    "# boix_track_matrix = val_loader._feature_indices_by_cell_type_index"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "with open(configs['dataset'][\"target_features_path\"]) as f:\n",
    "        target_features = list(map(lambda x: x.rstrip(), f.readlines()))\n",
    "\n",
    "with open(configs['dataset'][\"distinct_features_path\"]) as f:\n",
    "        distinct_features = list(map(lambda x: x.rstrip(), f.readlines()))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# all intervals\n",
    "genome_intervals = []\n",
    "with open(configs['dataset'][\"sampling_intervals_path\"])  as f:\n",
    "    for line in f:\n",
    "        chrom, start, end = interval_from_line(line)\n",
    "        genome_intervals.append((chrom, start, end))\n",
    "\n",
    "genome_intervals_arr = np.asarray(genome_intervals, dtype='U10,i8,i8')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "genome_intervals[:4], len(genome_intervals)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "([('chr1', 10500, 10680),\n",
       "  ('chr1', 713420, 714955),\n",
       "  ('chr1', 752395, 752905),\n",
       "  ('chr1', 753270, 753580)],\n",
       " 1377454)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "def get_full_dl(configs):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    if \"dataset\" in configs:\n",
    "        dataset_info = configs[\"dataset\"]\n",
    "\n",
    "        # all intervals\n",
    "        genome_intervals = []\n",
    "        with open(dataset_info[\"sampling_intervals_path\"])  as f:\n",
    "            for line in f:\n",
    "                chrom, start, end = interval_from_line(line)\n",
    "                genome_intervals.append((chrom, start, end))\n",
    "\n",
    "        print(len(genome_intervals))\n",
    "        # bedug\n",
    "        # genome_intervals = random.sample(genome_intervals, k=20)\n",
    "        # print(\"DEBUG MODE ON:\", len(genome_intervals))\n",
    "\n",
    "        with open(dataset_info[\"distinct_features_path\"]) as f:\n",
    "            distinct_features = list(map(lambda x: x.rstrip(), f.readlines()))\n",
    "\n",
    "        print(len(distinct_features))\n",
    "\n",
    "        with open(dataset_info[\"target_features_path\"]) as f:\n",
    "            target_features = list(map(lambda x: x.rstrip(), f.readlines()))\n",
    "\n",
    "        module = None\n",
    "        if os.path.isdir(dataset_info[\"path\"]):\n",
    "            module = module_from_dir(dataset_info[\"path\"])\n",
    "        else:\n",
    "            module = module_from_file(dataset_info[\"path\"])\n",
    "\n",
    "        dataset_class = getattr(module, dataset_info[\"class\"])\n",
    "        dataset_info[\"dataset_args\"][\"target_features\"] = target_features\n",
    "        dataset_info[\"dataset_args\"][\"distinct_features\"] = distinct_features\n",
    "\n",
    "        # load train dataset and loader\n",
    "        data_config = dataset_info[\"dataset_args\"].copy()\n",
    "        data_config[\"intervals\"] = genome_intervals\n",
    "\n",
    "        # train_config = dataset_info[\"dataset_args\"].copy()\n",
    "        del data_config['fold']\n",
    "        del data_config['n_folds']\n",
    "        # train_config[\"intervals\"] = genome_intervals\n",
    "        if \"train_transform\" in dataset_info:\n",
    "            # load transforms\n",
    "            train_transform = instantiate(dataset_info[\"train_transform\"])\n",
    "            data_config[\"transform\"] = train_transform\n",
    "        full_dataset = dataset_class(**data_config)\n",
    "        print(len(full_dataset))\n",
    "\n",
    "        # sampler_class = getattr(module, dataset_info[\"sampler_class\"])\n",
    "        # gen = torch.Generator()\n",
    "        # gen.manual_seed(configs[\"random_seed\"])\n",
    "        # train_sampler = sampler_class(\n",
    "        #     full_dataset, replacement=False, generator=gen\n",
    "        # )\n",
    "\n",
    "        # full_dataloader = torch.utils.data.DataLoader(\n",
    "        #     full_dataset,\n",
    "        #     batch_size=dataset_info[\"loader_args\"][\"batch_size\"],\n",
    "        #     num_workers=dataset_info[\"loader_args\"][\"num_workers\"],\n",
    "        #     worker_init_fn=module.encode_worker_init_fn,\n",
    "        #     sampler=train_sampler,\n",
    "        # )\n",
    "\n",
    "        return full_dataset  # full_dataloader\n",
    "\n",
    "\n",
    "full_dataset = get_full_dl(configs)\n",
    "# full_dataloader = get_full_dl(configs)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1377454\n",
      "631\n",
      "11576175\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "idx, retrieved_sample = full_dataset.__getitem__(0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "idx"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "len(retrieved_sample)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "for batch in full_dataloader:\n",
    "    idx, retrieved_sample = batch\n",
    "    1/0"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-d017c4504fbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfull_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretrieved_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "idx.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([256])"
      ]
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    " _, _, targets, _ = retrieved_sample\n",
    " targets.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([256, 631, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "mean_target = torch.mean(targets, dim=1).flatten() \n",
    "mean_target.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([256])"
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "source": [
    "torch.cat([idx, idx], dim=0).shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "metadata": {},
     "execution_count": 140
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "idx_np = idx.numpy()\n",
    "mean_target_np = mean_target.numpy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "y_cat = pd.cut(mean_target_np, 10, labels=range(10))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "# mean_target_np#.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "np.array(y_cat)#.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n",
       "       2, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 1, 0, 0, 0, 3, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 3, 0, 0, 8, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 9, 0, 0, 1, 0, 0, 0, 0, 0, 9, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0,\n",
       "       0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "train_idx = []\n",
    "val_idx = []\n",
    "train_y = []\n",
    "val_y = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "y_cat = np.array(y_cat)\n",
    "\n",
    "for train_index, val_index in skf.split(idx_np, y_cat):\n",
    "    train_idx.append(train_index)\n",
    "    val_idx.append(val_index)\n",
    "    train_y.append(y_cat[train_index])\n",
    "    val_y.append(y_cat[val_index])\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "len(train_idx)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "[c.shape for c in train_idx], [c.shape for c in val_idx]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "([(204,), (205,), (205,), (205,), (205,)], [(52,), (51,), (51,), (51,), (51,)])"
      ]
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "source": [
    "[Counter(i) for i in val_y]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[Counter({0: 46, 2: 2, 1: 3, 9: 1}),\n",
       " Counter({2: 2, 3: 1, 0: 46, 1: 2}),\n",
       " Counter({4: 1, 3: 1, 0: 46, 1: 2, 2: 1}),\n",
       " Counter({8: 1, 4: 1, 0: 46, 1: 2, 2: 1}),\n",
       " Counter({0: 46, 1: 3, 9: 1, 2: 1})]"
      ]
     },
     "metadata": {},
     "execution_count": 113
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(val_y);"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAALiklEQVR4nO3df6jd9X3H8edruUr6g1U7L+ISuxuoaMOkdQRnJ4wSW3CzVP+QYdtJGI4wsJvdCl3avzYY1MLojz9kJWi3wKStpIJixzoxljEYWW/UzWpazJxt42Jzy2rb7Y91Wd/7437dsntuck/uPfee+06eD5B7vp/z6+1X75Nvvud8NVWFJKmfn5n2AJKk1THgktSUAZekpgy4JDVlwCWpqZmNfLPLLrus5ubmNvItJam9I0eOfL+qZpeub2jA5+bmmJ+f38i3lKT2knx7uXVPoUhSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTG3ol5lrM7fvKyNpLWz8wsnbtjreMrD30iVMja4fedd/I2t2f273K6SRp43kELklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1NXbAk2xJ8nSSx4btHUkOJzmW5EtJLl6/MSVJS53LEfg9wNHTtj8JfLqq3gr8ALhrkoNJks5urIAn2Q7cAtw/bAfYDRwcHnIAuG0d5pMkncG4R+CfAT4K/HTY/jng1ao6NWwfB7Yt98Qke5PMJ5lfWFhYy6ySpNOsGPAk7wVOVtWR1bxBVe2vql1VtWt2dnY1LyFJWsbMGI+5EXhfkl8HtgI/C3wWuCTJzHAUvh14ef3GlCQtteIReFV9rKq2V9UccAdwqKo+CDwJ3D48bA/wyLpNKUkasZbvgf8h8AdJjrF4TvyByYwkSRrHOKdQ/ldVfQ342nD7ReD6yY8kSRqHV2JKUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKZWDHiSrUn+Ick/JnkuyR8P6zuSHE5yLMmXkly8/uNKkl4zzhH4fwK7q+rtwDuAm5PcAHwS+HRVvRX4AXDXuk0pSRqxYsBr0b8PmxcNfxWwGzg4rB8AbluPASVJyxvrHHiSLUmeAU4CjwP/DLxaVaeGhxwHtp3huXuTzCeZX1hYmMDIkiQYM+BV9d9V9Q5gO3A9cM24b1BV+6tqV1Xtmp2dXd2UkqQR5/QtlKp6FXgSeCdwSZKZ4a7twMuTHU2SdDbjfAtlNsklw+3XAe8BjrIY8tuHh+0BHlmnGSVJy5hZ+SFcARxIsoXF4D9UVY8leR74YpI/AZ4GHljHOSVJS6wY8Kr6J+C6ZdZfZPF8uCRpCrwSU5KaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1tWLAk1yZ5Mkkzyd5Lsk9w/qbkzye5IXh56XrP64k6TXjHIGfAj5SVTuBG4C7k+wE9gFPVNVVwBPDtiRpg6wY8Ko6UVVPDbd/DBwFtgG3AgeGhx0AblunGSVJyzinc+BJ5oDrgMPA5VV1YrjrFeDyMzxnb5L5JPMLCwtrmVWSdJqxA57kjcCXgQ9X1Y9Ov6+qCqjlnldV+6tqV1Xtmp2dXdOwkqT/M1bAk1zEYrwfrKqHh+XvJbliuP8K4OT6jChJWs4430IJ8ABwtKo+ddpdjwJ7htt7gEcmP54k6UxmxnjMjcCdwLNJnhnWPg7cCzyU5C7g28BvrMuEkqRlrRjwqvo7IGe4+6bJjiNJGpdXYkpSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekplYMeJLPJzmZ5Bunrb05yeNJXhh+Xrq+Y0qSlhrnCPwvgJuXrO0Dnqiqq4Anhm1J0gZaMeBV9bfAvy1ZvhU4MNw+ANw22bEkSStZ7Tnwy6vqxHD7FeDyMz0wyd4k80nmFxYWVvl2kqSl1vwhZlUVUGe5f39V7aqqXbOzs2t9O0nSYLUB/16SKwCGnycnN5IkaRyrDfijwJ7h9h7gkcmMI0ka1zhfI/wC8PfA1UmOJ7kLuBd4T5IXgHcP25KkDTSz0gOq6v1nuOumCc8iSToHXokpSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU3NTHuADub2fWVk7aV7b1n16933O4dG1u7+3O5Vv56kC5NH4JLUlAGXpKYMuCQ1ZcAlqSk/xFytP3rTyNK1O94ysvbQJ06NPvdd9439Nst+gLr1A8vM88OxX1PS+cEjcElqyoBLUlMGXJKa8hz4eeLaA9eOrC13/v3QMuffz+kiojHP/T+759nxX3MNxv37fts3j27EOJqCo9e8bWTtXP95T/JivY28UM8jcElqak0BT3Jzkm8lOZZk36SGkiStbNUBT7IFuA/4NWAn8P4kOyc1mCTp7NZyBH49cKyqXqyqnwBfBG6dzFiSpJWkqlb3xOR24Oaq+u1h+07gl6vqQ0setxfYO2xeDXzrHN7mMuD7qxrw/OU+GeU+GeU+GdV5n/xCVc0uXVz3b6FU1X5g/2qem2S+qnZNeKTW3Cej3Cej3Cejzsd9spZTKC8DV562vX1YkyRtgLUE/OvAVUl2JLkYuAN4dDJjSZJWsupTKFV1KsmHgK8CW4DPV9VzE5ts0apOvZzn3Cej3Cej3Cejzrt9suoPMSVJ0+WVmJLUlAGXpKY2ZcC9RH9UkiuTPJnk+STPJbln2jNtBkm2JHk6yWPTnmWzSHJJkoNJvpnkaJJ3TnumaUvy+8PvzTeSfCHJ1mnPNAmbLuBeon9Gp4CPVNVO4AbgbvcLAPcA/qcG/7/PAn9dVdcAb+cC3z9JtgG/B+yqql9k8UsXd0x3qsnYdAHHS/SXVVUnquqp4faPWfyl3DbdqaYryXbgFuD+ac+yWSR5E/CrwAMAVfWTqnp1qkNtDjPA65LMAK8H/nXK80zEZgz4NuC7p20f5wIP1VJJ5oDrgMNTHmXaPgN8FPjplOfYTHYAC8CfD6eW7k/yhmkPNU1V9TLwp8B3gBPAD6vqb6Y71WRsxoDrLJK8Efgy8OGq+tG055mWJO8FTlbVkWnPssnMAL8E/FlVXQf8B3BBf46U5FIW/xS/A/h54A1JfnO6U03GZgy4l+ifQZKLWIz3g1X18LTnmbIbgfcleYnF02y7k/zldEfaFI4Dx6vqtT+dHWQx6BeydwP/UlULVfVfwMPAr0x5ponYjAH3Ev1lJAmL5zWPVtWnpj3PtFXVx6pqe1XNsfjvyKGqOi+Oqtaiql4Bvpvk6mHpJuD5KY60GXwHuCHJ64ffo5s4Tz7Y3XT/T8wNukS/oxuBO4FnkzwzrH28qv5qeiNpk/pd4MHhAOhF4LemPM9UVdXhJAeBp1j8NtfTnCeX1XspvSQ1tRlPoUiSxmDAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLU1P8AYmdzo53e5fkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "source": [
    "plt.hist(train_y);"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "source": [
    "d = dict()\n",
    "for fold in range(len(train_idx)):\n",
    "    d[fold] = (train_idx[fold], train_y[fold], val_idx[fold], val_y[fold])\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "source": [
    "# d[4]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "source": [
    "res = pd.DataFrame.from_dict(d, orient='index', columns=['train_idx', 'train_y', 'val_idx', 'val_y'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "source": [
    "res.head()#['train_idx'][0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_idx</th>\n",
       "      <th>train_y</th>\n",
       "      <th>val_idx</th>\n",
       "      <th>val_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[19, 22, 31, 40, 53, 54, 55, 56, 57, 58, 59, 6...</td>\n",
       "      <td>[2, 2, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[19, 22, 40, 53, 54, 55, 56, 57, 58, 59, 61, 6...</td>\n",
       "      <td>[2, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[31, 70, 104, 105, 106, 107, 108, 109, 110, 11...</td>\n",
       "      <td>[4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[73, 114, 153, 154, 155, 156, 157, 158, 160, 1...</td>\n",
       "      <td>[8, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[202, 203, 204, 206, 208, 209, 210, 211, 212, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 9, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           train_idx  \\\n",
       "0  [19, 22, 31, 40, 53, 54, 55, 56, 57, 58, 59, 6...   \n",
       "1  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "2  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "3  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "4  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "\n",
       "                                             train_y  \\\n",
       "0  [2, 2, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                             val_idx  \\\n",
       "0  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "1  [19, 22, 40, 53, 54, 55, 56, 57, 58, 59, 61, 6...   \n",
       "2  [31, 70, 104, 105, 106, 107, 108, 109, 110, 11...   \n",
       "3  [73, 114, 153, 154, 155, 156, 157, 158, 160, 1...   \n",
       "4  [202, 203, 204, 206, 208, 209, 210, 211, 212, ...   \n",
       "\n",
       "                                               val_y  \n",
       "0  [0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [2, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [8, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 9, 0, 0, ...  "
      ]
     },
     "metadata": {},
     "execution_count": 145
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "len(genome_intervals_arr)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1377454"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "len(full_dataloader)#*256"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "45220"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "all_mean_targets = []\n",
    "\n",
    "for batch in tqdm(full_dataloader):\n",
    "    sequence_batch, _, targets, target_mask = batch\n",
    "    # print(targets.shape)\n",
    "    # 1/0\n",
    "    mean_target = torch.mean(targets, dim=0)\n",
    "    print(mean_target.shape)\n",
    "    1/0\n",
    "    # y_cat = pd.cut(y, 10, labels=range(10))\n",
    "    all_mean_targets.append(mean_target.numpy())\n",
    "    # retrieved_seq, retrieved_target = i\n",
    "    # print(retrieved_target)\n",
    "    # 1/0"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/45220 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([631, 1])\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/45220 [01:03<?, ?it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-f204598a6c22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmean_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;31m# y_cat = pd.cut(y, 10, labels=range(10))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mall_mean_targets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "targets.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([256, 631, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "torch.mean(targets, dim=1).flatten().shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([256])"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "tmp = [torch.mean(targets, dim=1).flatten(), torch.mean(targets, dim=1).flatten()]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "torch.cat(tmp, dim=0).shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "all_mean_targets = []\n",
    "all_mean_targets.append(mean_target.flatten())\n",
    "all_mean_targets = torch.cat(all_mean_targets, dim=0) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "all_mean_targets[:10]#.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0.1172, 0.0273, 0.0273, 0.0352, 0.0352, 0.0273, 0.0352, 0.0312, 0.0273,\n",
       "        0.0430])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "mean_target = torch.mean(targets, dim=0)#.shape\\\n",
    "# mean_target.numpy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "full_dataset._get_chrom_pos_cell_by_idx(4)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('chr1', 713720, 0)"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "genome_intervals[1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('chr1', 713420, 714955)"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "targets = _construct_target(\n",
    "    target_path=configs['dataset']['dataset_args']['target_path'],\n",
    "    distinct_features=distinct_features,\n",
    "    )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "targets"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<selene_sdk.targets.genomic_features.GenomicFeatures at 0x7f6aee481518>"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "bin_start = position - _start_radius\n",
    "bin_end = position + _end_radius\n",
    "targets_data = targets.get_feature_data(chrom, bin_start, bin_end)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "chrom, pos, cell_type_idx = full_dataset._get_chrom_pos_cell_by_idx(idx)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "len(torch.utils.data.Subset(full_dataset, idx))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "torch.utils.data.Subset(full_dataset, idx)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.Subset at 0x7f6acfd6eda0>"
      ]
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "means = np.load('results/all_targets_mean.npy')\n",
    "means.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(28533820,)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "means.shape[0]/631"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "45220.0"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "means[-10:]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.03603604, 0.05405406, 0.06306306, 0.05405406, 0.10810811,\n",
       "       0.        , 0.10810811, 0.00900901, 0.01801802, 0.03603604],\n",
       "      dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "len(genome_intervals_arr)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1377454"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "import pandas as pd\n",
    "\n",
    "y_cat = pd.cut(means, 10, labels=range(10))\n",
    "y_cat.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(28533820,)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Counter(y_cat)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({5: 27,\n",
       "         1: 795,\n",
       "         2: 475,\n",
       "         3: 276,\n",
       "         0: 218,\n",
       "         4: 73,\n",
       "         8: 5,\n",
       "         7: 11,\n",
       "         6: 10,\n",
       "         9: 3})"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "dataset_info = configs[\"dataset\"]\n",
    "\n",
    "# all intervals\n",
    "genome_intervals = []\n",
    "with open(dataset_info[\"sampling_intervals_path\"])  as f:\n",
    "    for line in f:\n",
    "        chrom, start, end = interval_from_line(line)\n",
    "        genome_intervals.append((chrom, start, end))\n",
    "\n",
    "genome_intervals[:10]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('chr1', 10500, 10680),\n",
       " ('chr1', 713420, 714955),\n",
       " ('chr1', 752395, 752905),\n",
       " ('chr1', 753270, 753580),\n",
       " ('chr1', 754045, 754605),\n",
       " ('chr1', 762595, 763055),\n",
       " ('chr1', 766170, 766430),\n",
       " ('chr1', 766595, 767180),\n",
       " ('chr1', 770945, 771205),\n",
       " ('chr1', 773070, 773355)]"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "len(genome_intervals), len(y_cat)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1377454, 1893)"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "genome_intervals_arr = np.asarray(genome_intervals, dtype='U10,i8,i8')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "train_intervals = []\n",
    "val_intervals = []\n",
    "train_y = []\n",
    "val_y = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "\n",
    "for train_index, val_index in skf.split(genome_intervals_arr, y_cat):\n",
    "    train_intervals.append(genome_intervals_arr[train_index])\n",
    "    val_intervals.append(genome_intervals_arr[val_index])\n",
    "    train_y.append(y_cat[train_index])\n",
    "    val_y.append(y_cat[val_index])\n",
    "    # print(train_index)\n",
    "    # print(genome_intervals_arr[train_index][:10])\n",
    "    # 1/0\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('chr1', 1767620, 1767905) ('chr1', 1783845, 1784355)\n",
      " ('chr1', 1811995, 1813705) ('chr1', 1814445, 1815505)\n",
      " ('chr1', 1818395, 1818780) ('chr1', 1819570, 1827930)\n",
      " ('chr1', 1828320, 1831780) ('chr1', 1837095, 1843680)\n",
      " ('chr1', 1868370, 1869405) ('chr1', 1869695, 1876330)]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-f696f452eec5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# print(train_index)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenome_intervals_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.save('results/stratified_train_intervals.npy', train_intervals)\n",
    "np.save('results/stratified_val_intervals.npy', val_intervals)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_skf_idx(genome_intervals, configs):\n",
    "\n",
    "    genome_intervals_arr = np.asarray(genome_intervals, dtype='U10,i8,i8')\n",
    "\n",
    "    k_fold = KFold(\n",
    "        configs['dataset']['dataset_args']['n_folds'], \n",
    "        shuffle=False, \n",
    "        # random_state=configs['random_seed'],\n",
    "    )\n",
    "    tr_idx_list = []\n",
    "    val_idx_list = []\n",
    "\n",
    "    for _, (tr_idx, val_idx) in enumerate(k_fold.split(genome_intervals_arr)):\n",
    "        tr_idx_list.append(tr_idx)\n",
    "        val_idx_list.append(val_idx)\n",
    "\n",
    "    return genome_intervals_arr, tr_idx_list, val_idx_list"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "###\n",
    "# fold = 1\n",
    "\n",
    "np.random.seed(14)\n",
    "n_features = 1\n",
    "\n",
    "\n",
    "for fold in range(n_folds):\n",
    "    print(fold)\n",
    "    gts = []\n",
    "    mean_preds = []\n",
    "    masks = []\n",
    "    for sample in tqdm(val_loader):\n",
    "        batch = copy.deepcopy(sample)\n",
    "        sequence_batch, _, targets, target_mask = batch\n",
    "        del sample\n",
    "\n",
    "        # make val mask\n",
    "        target_mask_tr = target_mask.clone()\n",
    "        target_mask_tr[:, ct_mask_range[fold][0]: ct_mask_range[fold][-1]] = False\n",
    "        # val mask\n",
    "        target_mask_val = ~target_mask_tr\n",
    "        masked_targets = targets * target_mask_val\n",
    "\n",
    "        1/0\n",
    "\n",
    "        mean_seq_val = (targets).sum(axis=1) / target_mask_val.sum(axis=1)\n",
    "        \n",
    "        mean_batch_pred = torch.repeat_interleave(mean_seq_val, n_cell_types, dim=0)\n",
    "        mean_batch_pred = mean_batch_pred.view(-1, n_features)\n",
    "        batch_gt = targets.view(-1, n_features)\n",
    "        #batch_mask = (target_mask_val).view(-1, n_features).astype(np.bool)\n",
    "        batch_mask = (target_mask_val).view(-1, n_features)\n",
    "        \n",
    "        # mask of samples to save for evaluation\n",
    "        save_mask = np.random.choice(mean_batch_pred.shape[0], mean_batch_pred.shape[0] // 16, replace=False)\n",
    "        \n",
    "        gts.append(batch_gt.data.numpy()[save_mask])\n",
    "        mean_preds.append(mean_batch_pred.data.numpy()[save_mask])\n",
    "        # masks for metric computation\n",
    "        masks.append(batch_mask.data.numpy()[save_mask])\n",
    "        del batch\n",
    "\n",
    "    gts = expand_dims(np.concatenate(gts))\n",
    "    np.save(f'results/gts_val_fold_{fold}.npy', gts)\n",
    "    \n",
    "    mean_preds = expand_dims(np.concatenate(mean_preds))\n",
    "    np.save(f'results/mean_preds_val_fold_{fold}.npy', mean_preds)\n",
    "    \n",
    "    masks = expand_dims(np.concatenate(masks))\n",
    "    np.save(f'results/masks_val_fold_{fold}.npy', masks)\n",
    "\n",
    "    map_val, ap_val = compute_score(\n",
    "        mean_preds, \n",
    "        gts, \n",
    "        average_precision_score, \n",
    "        target_mask=masks#.astype(np.bool)\n",
    "        )\n",
    "\n",
    "    del gts\n",
    "    del mean_preds\n",
    "    del masks\n",
    "    gc.colect()\n",
    "\n",
    "    print(fold, map_val, ap_val)\n",
    "\n",
    "    np.save(f'results/mean_pos_val_ap_fold_{fold}.npy', ap_val)\n",
    "    np.save(f'results/mean_pos_val_map_fold_{fold}.npy', map_val)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/36889 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-80d65ec198e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mmasked_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtarget_mask_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mmean_seq_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtarget_mask_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "gts = np.load('results/gts_val_fold_0.npy')\n",
    "mean_preds = np.load('results/mean_preds_val_fold_0.npy')\n",
    "masks = np.load('results/masks_val_fold_0.npy')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "gts[:10]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "mean_preds[:10]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.24603175],\n",
       "       [0.9126984 ],\n",
       "       [0.        ],\n",
       "       [0.06349207],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.00793651]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "masks[:10]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "map_val, ap_val = compute_score(\n",
    "    mean_preds, \n",
    "    gts, \n",
    "    average_precision_score, \n",
    "    target_mask=masks#.astype(np.bool)\n",
    "    )\n",
    "\n",
    "# np.save('mean_pos_val_ap_top4.npy', ap_val)\n",
    "# np.save('mean_pos_val_map_top4.npy', map_val)\n",
    "\n",
    "map_val, ap_val"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.56052681592646, array([0.56052682]))"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "gts_1 = np.load('results/gts_val_fold_1.npy')\n",
    "mean_preds_1 = np.load('results/mean_preds_val_fold_1.npy')\n",
    "masks_1 = np.load('results/masks_val_fold_1.npy')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "map_val_1, ap_val_1 = compute_score(\n",
    "    mean_preds_1, \n",
    "    gts_1, \n",
    "    average_precision_score, \n",
    "    target_mask=masks_1#.astype(np.bool)\n",
    "    )\n",
    "\n",
    "map_val_1, ap_val_1"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.545688774106069, array([0.54568877]))"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "base_scores_tr = []\n",
    "base_scores_val = []\n",
    "\n",
    "for fold, (tr_idx, val_idx) in enumerate(k_fold.split(genome_intervals_arr)):\n",
    "    print(fold)\n",
    "\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        sequence_batch, _, targets, target_mask = batch\n",
    "        print(targets)\n",
    "        print(targets.shape)\n",
    "        print(target_mask.sum())\n",
    "        \n",
    "        # make train mask\n",
    "        target_mask_tr = target_mask.clone()\n",
    "        target_mask_tr[:, ct_mask_range[fold][0]: ct_mask_range[fold][-1]] = False\n",
    "        print(target_mask_tr.sum())\n",
    "\n",
    "        targets *= target_mask_tr\n",
    "        print(targets)\n",
    "\n",
    "        mean_seq_val = (targets).sum(axis=1) / target_mask_tr.sum(axis=1)\n",
    "        print(mean_seq_val)\n",
    "        mean_seq_batch = torch.repeat_interleave(mean_seq_val.unsqueeze(1), configs['model']['class_args']['n_cell_types'], dim=1)    \n",
    "        print(mean_seq_batch.shape)\n",
    "        \n",
    "        # base_score = average_precision_score(mean_seq_batch, targets)\n",
    "        # print('base_score', base_score)\n",
    "        # base_scores_val.append(base_score)    \n",
    "\n",
    "        1/0\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "tensor([[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]])\n",
      "torch.Size([2, 631, 1])\n",
      "tensor(1262)\n",
      "tensor(1136)\n",
      "tensor([[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]])\n",
      "tensor([[0.0018],\n",
      "        [0.1884]])\n",
      "torch.Size([2, 631, 1])\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-266592d5671d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# base_scores_val.append(base_score)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "base_score = average_precision_score(mean_seq_batch.numpy(), targets.numpy())\n",
    "base_score"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "unknown format is not supported",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-977c3cfffb0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbase_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage_precision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_seq_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbase_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/genv/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/genv/lib/python3.6/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36maverage_precision_score\u001b[0;34m(y_true, y_score, average, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    223\u001b[0m                                 pos_label=pos_label)\n\u001b[1;32m    224\u001b[0m     return _average_binary_score(average_precision, y_true, y_score,\n\u001b[0;32m--> 225\u001b[0;31m                                  average, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/genv/lib/python3.6/site-packages/sklearn/metrics/_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: unknown format is not supported"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "mean_seq_batch.numpy()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[[0.00176056],\n",
       "        [0.00176056],\n",
       "        [0.00176056],\n",
       "        ...,\n",
       "        [0.00176056],\n",
       "        [0.00176056],\n",
       "        [0.00176056]],\n",
       "\n",
       "       [[0.18838029],\n",
       "        [0.18838029],\n",
       "        [0.18838029],\n",
       "        ...,\n",
       "        [0.18838029],\n",
       "        [0.18838029],\n",
       "        [0.18838029]]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "targets"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]])"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "mean_seq_batch"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[0.0018],\n",
       "         [0.0018],\n",
       "         [0.0018],\n",
       "         ...,\n",
       "         [0.0018],\n",
       "         [0.0018],\n",
       "         [0.0018]],\n",
       "\n",
       "        [[0.1884],\n",
       "         [0.1884],\n",
       "         [0.1884],\n",
       "         ...,\n",
       "         [0.1884],\n",
       "         [0.1884],\n",
       "         [0.1884]]])"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "base_score = average_precision_score(mean_seq_batch, targets)\n",
    "print('base_score', base_score)\n",
    "base_scores_val.append(base_score)    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# K-fold\n",
    "## Stratified K-fold"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "genome_intervals = []\n",
    "with open(cfg.datamodule.sampling_intervals_path) as f:\n",
    "    for line in f:\n",
    "        chrom, start, end = interval_from_line(line)\n",
    "        genome_intervals.append((chrom, start, end))\n",
    "\n",
    "print(len(genome_intervals))\n",
    "\n",
    "genome_intervals_arr = np.asarray(genome_intervals, dtype='U10,i8,i8')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1377454\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "genome_intervals_arr[:10]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([('chr1',  10500,  10680), ('chr1', 713420, 714955),\n",
       "       ('chr1', 752395, 752905), ('chr1', 753270, 753580),\n",
       "       ('chr1', 754045, 754605), ('chr1', 762595, 763055),\n",
       "       ('chr1', 766170, 766430), ('chr1', 766595, 767180),\n",
       "       ('chr1', 770945, 771205), ('chr1', 773070, 773355)],\n",
       "      dtype=[('f0', '<U10'), ('f1', '<i8'), ('f2', '<i8')])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "train_transforms = transforms.Compose([\n",
    "            PermuteSequenceChannels(), \n",
    "            RandomReverseStrand(p=0.5)\n",
    "        ])\n",
    "        \n",
    "val_transform = PermuteSequenceChannels()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss(reduction='sum')\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr = 0.0001, weight_decay = 1e-6)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "train_loader.batch_size"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "tr_idx_list = []\n",
    "val_idx_list = []\n",
    "\n",
    "for fold, (tr_idx, val_idx) in enumerate(k_fold.split(genome_intervals_arr)):\n",
    "    # print(fold)\n",
    "    tr_idx_list.append(tr_idx)\n",
    "    val_idx_list.append(val_idx)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "val_idx_list[:3]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[array([     0,      1,      2, ..., 137743, 137744, 137745]),\n",
       " array([137746, 137747, 137748, ..., 275489, 275490, 275491]),\n",
       " array([275492, 275493, 275494, ..., 413235, 413236, 413237])]"
      ]
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "len(tr_idx_list[9])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1239709"
      ]
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "# ct_mask_idx = np.array_split(range(cfg.model.params.n_cell_types), 10)\n",
    "# genome_intervals_arr = np.asarray(genome_intervals, dtype='U10,i8,i8')\n",
    "model_scores_tr = []\n",
    "base_scores_tr = []\n",
    "model_scores_val = []\n",
    "base_scores_val = []\n",
    "\n",
    "\n",
    "model = DeepCT(m_cfg)\n",
    "model.train()\n",
    "\n",
    "for fold, (tr_idx, val_idx) in enumerate(k_fold.split(genome_intervals_arr)):\n",
    "    print(fold)\n",
    "\n",
    "    # train/val split\n",
    "    tr_intervals = genome_intervals_arr[tr_idx].tolist()\n",
    "    val_intervals = genome_intervals_arr[val_idx].tolist()\n",
    "\n",
    "    train_dataset = load_obj(cfg.datamodule.class_name)(\n",
    "            cfg=cfg,\n",
    "            distinct_features=distinct_features,\n",
    "            target_features=target_features,\n",
    "            intervals=tr_intervals,\n",
    "            transform=train_transforms,\n",
    "        )\n",
    "    val_dataset = load_obj(cfg.datamodule.class_name)(\n",
    "            cfg=cfg,\n",
    "            distinct_features=distinct_features,\n",
    "            target_features=target_features,\n",
    "            intervals=val_intervals,\n",
    "            transform=train_transforms,\n",
    "        )\n",
    "    \n",
    "    train_loader = get_loader(train_dataset, batch_size=2, num_workers=1, shuffle=666)\n",
    "    val_loader = get_loader(val_dataset, batch_size=2, num_workers=1, shuffle=666)\n",
    "\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        sequence_batch, _, targets, target_mask = batch\n",
    "        \n",
    "        # make train mask\n",
    "        target_mask_tr = target_mask.clone()\n",
    "        target_mask_tr[:, ct_mask_idx[fold][0]: ct_mask_idx[fold][-1]] = False\n",
    "        \n",
    "        logits = model(sequence_batch)\n",
    "        # predictions = torch.sigmoid(logits)*target_mask_tr#.view(train_loader.batch_size, cfg.model.params.n_cell_types, 1)\n",
    "\n",
    "        criterion.weight = target_mask_tr\n",
    "        loss = criterion(predictions, targets.float())\n",
    "        loss = loss / criterion.weight.sum()\n",
    "        print(\"train loss:\", loss.item())\n",
    "\n",
    "        \n",
    "        # model_score = avg_pr(predictions[target_mask_tr], targets[target_mask_tr])\n",
    "        # model_scores_tr.append(model_score)\n",
    "        # base_score = avg_pr(mean_seq_batch[target_mask_tr], targets[target_mask_tr])\n",
    "\n",
    "        # optimizer.zero_grad()\n",
    "        # loss.backward(retain_graph=True)\n",
    "        # optimizer.step()\n",
    "\n",
    "        if i >= 2:\n",
    "            break\n",
    "\n",
    "    for batch in val_loader:\n",
    "        sequence_batch, _, targets, target_mask = batch\n",
    "\n",
    "        # val mask\n",
    "        target_mask_val = ~target_mask_tr\n",
    "\n",
    "        targets = targets * target_mask_val\n",
    "        \n",
    "        # compute baseline\n",
    "        mean_seq_val = (targets * target_mask_val).sum(axis=1) / target_mask_val.sum(axis=1)\n",
    "        print('mean_seq_val', mean_seq_val)\n",
    "        mean_seq_batch = torch.repeat_interleave(mean_seq_val.unsqueeze(1), cfg.model.params.n_cell_types, dim=1)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            logits = model(sequence_batch)\n",
    "            predictions = torch.sigmoid(logits)#[target_mask_val].view(val_loader.batch_size, cfg.model.params.n_cell_types, 1)\n",
    "            predictions = predictions*target_mask_val\n",
    "\n",
    "            criterion.weight = target_mask_val\n",
    "            loss = criterion(predictions, targets.float())\n",
    "            loss = loss / criterion.weight.sum()\n",
    "\n",
    "\n",
    "            model_score_val = avg_pr(predictions, targets)\n",
    "            model_scores_val.append(model_score_val)\n",
    "\n",
    "            base_score = avg_pr(mean_seq_batch, targets)\n",
    "            print('base_score', base_score)\n",
    "            base_scores_val.append(base_score)\n",
    "\n",
    "        print(\"val loss:\", loss.item())\n",
    "\n",
    "        if i >= 2:\n",
    "            break\n",
    "\n",
    "    break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "train loss: 0.9745064377784729\n",
      "train loss: 0.9696027636528015\n",
      "train loss: 0.9762895703315735\n",
      "mean_seq_val tensor([[0.0159],\n",
      "        [0.0000]])\n",
      "base_score tensor(0.0016)\n",
      "val loss: 0.9698627591133118\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# проверить подсчет baseline\n",
    "# подумать как сохранять модели\n",
    "# впилить это всё в DeepCT"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "target_mask_val.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([2, 631, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "mean_seq_batch = torch.repeat_interleave(mean_seq_val.unsqueeze(1), cfg.model.params.n_cell_types, dim=1)\n",
    "mean_seq_batch.shape\n",
    "# mean_seq_batch = mean_seq_batch[target_mask_val]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([2, 631, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "mean_seq_batch = mean_seq_batch*target_mask_val\n",
    "mean_seq_batch.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([2, 631, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "target_mask_val.sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'class_name': 'pipeline.models.deepct_model_multi_ct.DeepCT', 'params': {'sequence_length': 1000, 'n_cell_types': 631, 'sequence_embedding_length': 256, 'cell_type_embedding_length': 32, 'final_embedding_length': 256, 'n_genomic_features': 1, 'conv_kernel_size': 8, 'pool_kernel_size': 4}}"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "dataset_class = getattr(module, dataset_info[\"class\"])\n",
    "\n",
    "load_train_val = False\n",
    "load_test = False\n",
    "\n",
    "if \"dataset\" in configs:\n",
    "    dataset_info = configs[\"dataset\"]\n",
    "    genome_intervals = []\n",
    "    # genome_intervals = np.array([])\n",
    "    with open(dataset_info[\"sampling_intervals_path\"]) as f:\n",
    "        for line in f:\n",
    "            chrom, start, end = line.rstrip().split(\"\\t\")[:3]\n",
    "            start = int(start)\n",
    "            end = int(end)\n",
    "            genome_intervals.append((chrom, start, end))\n",
    "            # genome_intervals = np.append(genome_intervals, (chrom, start, end))\n",
    "            \n",
    "    with open(dataset_info[\"distinct_features_path\"]) as f:\n",
    "        distinct_features = list(map(lambda x: x.rstrip(), f.readlines()))\n",
    "\n",
    "    with open(dataset_info[\"target_features_path\"]) as f:\n",
    "        target_features = list(map(lambda x: x.rstrip(), f.readlines()))\n",
    "\n",
    "dataset_info[\"dataset_args\"][\"target_features\"] = target_features\n",
    "dataset_info[\"dataset_args\"][\"distinct_features\"] = distinct_features\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "genome_intervals[:5], len(genome_intervals)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "([('chr1', 10500, 10680),\n",
       "  ('chr1', 713420, 714955),\n",
       "  ('chr1', 752395, 752905),\n",
       "  ('chr1', 753270, 753580),\n",
       "  ('chr1', 754045, 754605)],\n",
       " 1377454)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "distinct_features[:5], len(distinct_features)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(['8988T|DNase-seq|None',\n",
       "  'A172|DNase-seq|None',\n",
       "  'A549_treated_with_100_nM_dexamethasone_for_10_hours|DNase-seq|None',\n",
       "  'A549_treated_with_100_nM_dexamethasone_for_12_hours|DNase-seq|None',\n",
       "  'A549_treated_with_100_nM_dexamethasone_for_1_hour|DNase-seq|None'],\n",
       " 631)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# distinct_features == tracks (feature + cell_type)\n",
    "data_config = dataset_info[\"dataset_args\"].copy()\n",
    "data_config[\"intervals\"] = genome_intervals"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "fold = KFold(10, shuffle=False)\n",
    "# fold = KFold(10, shuffle=True, random_state=666)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "data_config = dataset_info[\"dataset_args\"].copy()\n",
    "data_config[\"intervals\"] = genome_intervals\n",
    "\n",
    "full_dataset = dataset_class(**data_config)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# train_dataset.__getitem__(0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# genome_intervals#_arr"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# np.asarray(genome_intervals, dtype='U10,i8,i8')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# 1 - loc folds\n",
    "\n",
    "batch_size = dataset_info['loader_args']['batch_size']\n",
    "train_transform = instantiate(dataset_info[\"train_transform\"])\n",
    "val_transform = PermuteSequenceChannels()\n",
    "\n",
    "sampler_class = getattr(module, dataset_info[\"sampler_class\"])\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(configs[\"random_seed\"])\n",
    "\n",
    "\n",
    "genome_intervals_arr = np.asarray(genome_intervals, dtype='U10,i8,i8')\n",
    "\n",
    "for f, (tr_idx, val_idx) in enumerate(fold.split(genome_intervals_arr)):\n",
    "    tr_intervals = genome_intervals_arr[tr_idx].tolist()\n",
    "    val_intervals = genome_intervals_arr[val_idx].tolist()\n",
    "\n",
    "    train_config = dataset_info[\"dataset_args\"].copy()\n",
    "    train_config[\"intervals\"] = tr_intervals\n",
    "    train_config[\"transform\"] = train_transform\n",
    "\n",
    "    val_config = dataset_info[\"dataset_args\"].copy()\n",
    "    val_config[\"intervals\"] = val_intervals\n",
    "    val_config[\"transform\"] = val_transform\n",
    "\n",
    "    train_dataset = dataset_class(**train_config)\n",
    "    val_dataset = dataset_class(**val_config)\n",
    "\n",
    "    train_sampler = sampler_class(\n",
    "        train_dataset, replacement=False, generator=gen)\n",
    "\n",
    "    val_sampler = sampler_class(\n",
    "        val_dataset, replacement=False, generator=gen)\n",
    "\n",
    "\n",
    "    # train_dataset = GenSubset(full_dataset, tr_idx, transform=train_transform)\n",
    "    # val_dataset = GenSubset(full_dataset, val_idx, transform=val_transform)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                            batch_size=batch_size,\n",
    "                                            num_workers=dataset_info[\"loader_args\"][\"num_workers\"],\n",
    "                                            worker_init_fn=module.encode_worker_init_fn,\n",
    "                                            sampler=train_sampler,\n",
    "                                        )\n",
    "    val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                            batch_size=batch_size,\n",
    "                                            num_workers=dataset_info[\"loader_args\"][\"num_workers\"],\n",
    "                                            worker_init_fn=module.encode_worker_init_fn,\n",
    "                                            sampler=val_sampler,\n",
    "                                        )\n",
    "\n",
    "    print(len(train_loader), len(val_loader))\n",
    "\n",
    "\n",
    "\n",
    "    1/0"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1032815 124804\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-1704bfe5effa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "for f, (tr_idx, val_idx) in enumerate(fold.split(genome_intervals_arr)):\n",
    "    tr_intervals = genome_intervals_arr[tr_idx].tolist()\n",
    "    val_intervals = genome_intervals_arr[val_idx].tolist()\n",
    "\n",
    "    print(f, val_idx)\n",
    "    # 1/0"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 [     0      1      2 ... 137743 137744 137745]\n",
      "1 [137746 137747 137748 ... 275489 275490 275491]\n",
      "2 [275492 275493 275494 ... 413235 413236 413237]\n",
      "3 [413238 413239 413240 ... 550981 550982 550983]\n",
      "4 [550984 550985 550986 ... 688726 688727 688728]\n",
      "5 [688729 688730 688731 ... 826471 826472 826473]\n",
      "6 [826474 826475 826476 ... 964216 964217 964218]\n",
      "7 [ 964219  964220  964221 ... 1101961 1101962 1101963]\n",
      "8 [1101964 1101965 1101966 ... 1239706 1239707 1239708]\n",
      "9 [1239709 1239710 1239711 ... 1377451 1377452 1377453]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "from pipeline.models.deepct_model_multi_ct import DeepCT\n",
    "\n",
    "model = DeepCT(**configs['model']['class_args'])\n",
    "model.train()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DeepCT(\n",
       "  (conv_net): Sequential(\n",
       "    (0): Conv1d(4, 320, kernel_size=(8,), stride=(1,))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv1d(320, 320, kernel_size=(8,), stride=(1,))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Conv1d(320, 480, kernel_size=(8,), stride=(1,))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv1d(480, 480, kernel_size=(8,), stride=(1,))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): BatchNorm1d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): Dropout(p=0.2, inplace=False)\n",
       "    (13): Conv1d(480, 960, kernel_size=(8,), stride=(1,))\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): Conv1d(960, 960, kernel_size=(8,), stride=(1,))\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): BatchNorm1d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (18): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (sequence_net): Sequential(\n",
       "    (0): Linear(in_features=42240, out_features=256, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (cell_type_net): Sequential(\n",
       "    (0): Linear(in_features=631, out_features=32, bias=True)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=288, out_features=256, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "# retrieved_seq, cell_type, target, target_mask\n",
    "sequence_batch = batch[0]#.to(device)\n",
    "cell_type_batch = batch[1]#.to(device)\n",
    "targets = batch[2]#.to(device)\n",
    "target_mask = batch[3]#.to(device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "targets.shape, target_mask.shape, cell_type_batch.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([10, 631, 1]), torch.Size([10, 631, 1]), torch.Size([10]))"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "target_mask.shape[1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "631"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss(reduction='sum')\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr = 0.0001, weight_decay = 1e-6)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "criterion.reduction"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'sum'"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "optimizer"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.0001\n",
       "    weight_decay: 1e-06\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "model = DeepCT(**configs['model']['class_args'])\n",
    "model.train()\n",
    "\n",
    "\n",
    "batch_size = dataset_info['loader_args']['batch_size']\n",
    "train_transform = instantiate(dataset_info[\"train_transform\"])\n",
    "val_transform = PermuteSequenceChannels()\n",
    "\n",
    "sampler_class = getattr(module, dataset_info[\"sampler_class\"])\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(configs[\"random_seed\"])\n",
    "\n",
    "ct_mask_idx = np.array_split(range(configs['model']['class_args']['n_cell_types']), 10)\n",
    "\n",
    "genome_intervals_arr = np.asarray(genome_intervals, dtype='U10,i8,i8')\n",
    "\n",
    "for f, (tr_idx, val_idx) in enumerate(fold.split(genome_intervals_arr)):\n",
    "    tr_intervals = genome_intervals_arr[tr_idx].tolist()\n",
    "    val_intervals = genome_intervals_arr[val_idx].tolist()\n",
    "\n",
    "    train_config = dataset_info[\"dataset_args\"].copy()\n",
    "    train_config[\"intervals\"] = tr_intervals\n",
    "    train_config[\"transform\"] = train_transform\n",
    "\n",
    "    val_config = dataset_info[\"dataset_args\"].copy()\n",
    "    val_config[\"intervals\"] = val_intervals\n",
    "    val_config[\"transform\"] = val_transform\n",
    "\n",
    "    train_dataset = dataset_class(**train_config)\n",
    "    val_dataset = dataset_class(**val_config)\n",
    "\n",
    "    train_sampler = sampler_class(\n",
    "        train_dataset, replacement=False, generator=gen)\n",
    "\n",
    "    val_sampler = sampler_class(\n",
    "        val_dataset, replacement=False, generator=gen)\n",
    "\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                            batch_size=batch_size,\n",
    "                                            num_workers=dataset_info[\"loader_args\"][\"num_workers\"],\n",
    "                                            worker_init_fn=module.encode_worker_init_fn,\n",
    "                                            sampler=train_sampler,\n",
    "                                        )\n",
    "    val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                            batch_size=batch_size,\n",
    "                                            num_workers=dataset_info[\"loader_args\"][\"num_workers\"],\n",
    "                                            worker_init_fn=module.encode_worker_init_fn,\n",
    "                                            sampler=val_sampler,\n",
    "                                        )\n",
    "\n",
    "    for batch in train_loader:\n",
    "        sequence_batch = batch[0]#.to(device)\n",
    "        cell_type_batch = batch[1]#.to(device)\n",
    "        targets = batch[2]#.to(device)\n",
    "        target_mask = batch[3]#.to(device)\n",
    "        \n",
    "        target_mask_tr = target_mask.clone()\n",
    "        target_mask_tr[:, ct_mask_idx[f][0]: ct_mask_idx[f][-1]] = False\n",
    "        \n",
    "        outputs = model(sequence_batch, cell_type_batch)\n",
    "\n",
    "        criterion.weight = target_mask_tr\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss = loss / criterion.weight.sum()\n",
    "        print(\"train loss:\", loss.item())\n",
    "\n",
    "        predictions = torch.sigmoid(outputs)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        break\n",
    "\n",
    "    break\n",
    "\n",
    "    # for batch in val_loader:\n",
    "    #     sequence_batch = batch[0]#.to(device)\n",
    "    #     cell_type_batch = batch[1]#.to(device)\n",
    "    #     targets = batch[2]#.to(device)\n",
    "    #     target_mask = batch[3]#.to(device)\n",
    "\n",
    "    #     # val mask\n",
    "    #     target_mask_val = ~target_mask\n",
    "\n",
    "    #     model.eval()\n",
    "    #     with torch.no_grad():\n",
    "    #         outputs = model(sequence_batch, cell_type_batch)\n",
    "\n",
    "    #         criterion.weight = target_mask_val\n",
    "    #         loss = criterion(outputs, targets)\n",
    "    #         loss = loss / criterion.weight.sum()\n",
    "\n",
    "    #         val_predictions = torch.sigmoid(outputs)\n",
    "\n",
    "\n",
    "    #     print(\"val loss:\", loss.item())\n",
    "\n",
    "\n",
    "        # break\n",
    "\n",
    "    # 1/0\n",
    "\n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train loss: 0.00011682936747092754\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "# ct_mask_idx = np.array_split(range(configs['model']['class_args']['n_cell_types']), 10)\n",
    "# [len(c) for c in ct_mask_idx]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[64, 63, 63, 63, 63, 63, 63, 63, 63, 63]"
      ]
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "criterion.weight[1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]])"
      ]
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "criterion.weight[1].sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(568)"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "for batch in val_loader:\n",
    "    sequence_batch = batch[0]#.to(device)\n",
    "    cell_type_batch = batch[1]#.to(device)\n",
    "    targets = batch[2]#.to(device)\n",
    "    # target_mask = batch[3]#.to(device)\n",
    "\n",
    "    # val mask\n",
    "    target_mask_val = ~target_mask_tr\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(sequence_batch, cell_type_batch)\n",
    "\n",
    "        criterion.weight = target_mask_val\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss = loss / criterion.weight.sum()\n",
    "\n",
    "        val_predictions = torch.sigmoid(outputs)\n",
    "\n",
    "\n",
    "    print(\"val loss:\", loss.item())\n",
    "    break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val loss: 0.0001089841389330104\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "criterion.weight[1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False]])"
      ]
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "criterion.weight[1].sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(63)"
      ]
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "source": [
    "sequence_batch.shape, cell_type_batch.shape, targets.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([10, 4, 1000]), torch.Size([10]), torch.Size([10, 631, 1]))"
      ]
     },
     "metadata": {},
     "execution_count": 141
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "source": [
    "outputs = model(sequence_batch, cell_type_batch)\n",
    "outputs.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([10, 631, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 144
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "source": [
    "criterion.weight = target_mask_tr\n",
    "loss = criterion(outputs, targets)\n",
    "loss = loss / criterion.weight.sum()\n",
    "loss.item()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(0.0001, grad_fn=<DivBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 145
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "source": [
    "predictions = torch.sigmoid(outputs)\n",
    "predictions.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([10, 631, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 147
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "source": [
    "model.eval()\n",
    "\n",
    "for val_batch in val_loader:\n",
    "    val_sequence_batch = val_batch[0]#.to(device)\n",
    "    val_cell_type_batch = val_batch[1]#.to(device)\n",
    "    val_targets = val_batch[2]#.to(device)\n",
    "    val_target_mask = val_batch[3]#.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(val_sequence_batch, val_cell_type_batch)\n",
    "\n",
    "        criterion.weight = target_mask_val\n",
    "        loss = criterion(outputs, val_targets)\n",
    "        loss = loss / criterion.weight.sum()\n",
    "\n",
    "        val_predictions = torch.sigmoid(outputs)\n",
    "\n",
    "        break\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "source": [
    "loss.item()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.00010881867638090625"
      ]
     },
     "metadata": {},
     "execution_count": 150
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "source": [
    "val_predictions#.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[0.4966],\n",
       "         [0.4966],\n",
       "         [0.4966],\n",
       "         ...,\n",
       "         [0.4966],\n",
       "         [0.4966],\n",
       "         [0.4966]],\n",
       "\n",
       "        [[0.4966],\n",
       "         [0.4966],\n",
       "         [0.4966],\n",
       "         ...,\n",
       "         [0.4966],\n",
       "         [0.4966],\n",
       "         [0.4966]],\n",
       "\n",
       "        [[0.4966],\n",
       "         [0.4966],\n",
       "         [0.4966],\n",
       "         ...,\n",
       "         [0.4966],\n",
       "         [0.4966],\n",
       "         [0.4966]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.4966],\n",
       "         [0.4966],\n",
       "         [0.4966],\n",
       "         ...,\n",
       "         [0.4966],\n",
       "         [0.4966],\n",
       "         [0.4966]],\n",
       "\n",
       "        [[0.4966],\n",
       "         [0.4966],\n",
       "         [0.4966],\n",
       "         ...,\n",
       "         [0.4966],\n",
       "         [0.4966],\n",
       "         [0.4966]],\n",
       "\n",
       "        [[0.4966],\n",
       "         [0.4966],\n",
       "         [0.4966],\n",
       "         ...,\n",
       "         [0.4966],\n",
       "         [0.4966],\n",
       "         [0.4966]]])"
      ]
     },
     "metadata": {},
     "execution_count": 155
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit ('genv': venv)"
  },
  "interpreter": {
   "hash": "7bed6a5b8f0827f7d7f30ba9d7b2c61fcd2f223009d9afc95ff59e669a7c4ade"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}