---
ops: [train]
lr: 0.0001
lr_scheduler: {
    class: !import torch.optim.lr_scheduler.CosineAnnealingLR,
    class_args: {
        T_max: 1750020,
    }
}
model: {
    path: src/deepct_model_multi_ct_q_mpi.py,
    class: qDeepCT,
    class_args:{
        sequence_length: 1000,
        n_cell_types: 794,
        sequence_embedding_length: 256,
        cell_type_embedding_length: 32,
        final_embedding_length: 256,
        n_genomic_features: 40,
        dropout_rate: 0.3
    }
}

dataset: {
    path: src/dataset.py,
    class: EncodeDataset,
    train_sampler_class: LargeRandomSampler,
    validation_sampler_class: SubsetRandomSampler,
    validation_sampler_args: {num_samples: 1600},

    distinct_features_path: /home/jovyan/datasets/DeepCT/dataset_data/q_features_all/distinct_features_nonTreated.qcfiltered.txt,
    target_features_path: /home/jovyan/datasets/DeepCT/dataset_data/q_features_all/target_features.txt,
    sampling_intervals_path: /home/jovyan/datasets/DeepCT/dataset_data/q_features_all/target_intervals_wo_chrY.bed,
    test_holdout: [chr8, chr9],
    validation_holdout: [chr6, chr7],

    dataset_args: {
        reference_sequence_path: /home/jovyan/datasets/DeepCT/male.hg19.fasta,
        target_path: /home/jovyan/datasets/DeepCT/dataset_data/q_features_mask_all/features2files_mapping_nonTreated.updated_paths.txt,
        # masked_tracks_path: /home/jovyan/datasets/DeepCT/dataset_data/q_features_mask_all/masked_tracks.txt,
        cell_wise: True,
        multi_ct_target: True,
        sequence_length: 1000,
        center_bin_to_predict: 200,
        feature_thresholds: 0.5,
        position_skip: 100,
        quantitative_features: True,
    },
    loader_args: {
        batch_size: 64,
        num_workers: 8,
    },
    train_transform: !obj:torchvision.transforms.Compose {
        transforms: [
            !obj:src.transforms.PermuteSequenceChannels {},
            !obj:src.transforms.RandomReverseStrand {
                p: 0.5,
            },
            !obj:src.transforms.LogTargets {
                pseudocount: 0.001
            },
            !obj:src.transforms.ClipTargets {
              amin: -1.0,
              amax: 4.0
            }
        ]
    },
    validation_transform: !obj:torchvision.transforms.Compose {
        transforms: [
            !obj:src.transforms.PermuteSequenceChannels {},
            !obj:src.transforms.LogTargets {
                pseudocount: 0.001
            }
        ]
    }
}

quant2prob_transform: &quant2prob_transform !obj:torchvision.transforms.Compose {
  transforms: [  
    !obj:src.transforms.MeanAndDeviation2AbsolutePrediction {
        transform_predictions: True,
        transform_targets: False
    },
    !obj:src.transforms.Quantitative2Sigmoid {
        transform_predictions: True,
        transform_targets: False,
        threshold: 1.4816
    },
    !obj:src.transforms.Quantitative2Qualitative {
        transform_predictions: False,
        transform_targets: True,
        threshold: 1.4816
    },
    !obj:src.transforms.Concat_batches {
        transform_predictions: True,
        transform_targets: True,
        transform_masks: True,
    }]
}

quant2prob_transform_masked_tracks: &quant2prob_transform_masked_tracks !obj:torchvision.transforms.Compose {
  transforms: [
    !obj:src.transforms.InvertMaskedTracks {},
    !obj:src.transforms.MeanAndDeviation2AbsolutePrediction {
        transform_predictions: True,
        transform_targets: False
    },
    !obj:src.transforms.Quantitative2Sigmoid {
        transform_predictions: True,
        transform_targets: False,
        threshold: 1.4816
    },
    !obj:src.transforms.Quantitative2Qualitative {
        transform_predictions: False,
        transform_targets: True,
        threshold: 1.4816
    },
    !obj:src.transforms.Concat_batches {
        transform_predictions: True,
        transform_targets: True,
        transform_masks: True,
    }]
}

batch_merging_transform: &batch_merging_transform !obj:torchvision.transforms.Compose {
  transforms: [  
    !obj:src.transforms.MeanAndDeviation2AbsolutePrediction {
        transform_predictions: True,
        transform_targets: False
    },
    !obj:src.transforms.Concat_batches {
        transform_predictions: True,
        transform_targets: True,
        transform_masks: True,
    }
    ]
}

batch_merging_transform_masked_tracks: &batch_merging_transform_masked_tracks !obj:torchvision.transforms.Compose {
  transforms: [  
    !obj:src.transforms.InvertMaskedTracks {},
    !obj:src.transforms.MeanAndDeviation2AbsolutePrediction {
        transform_predictions: True,
        transform_targets: False
    },
    !obj:src.transforms.Concat_batches {
        transform_predictions: True,
        transform_targets: True,
        transform_masks: True,
    }
    ]
}

train_model: !obj:src.train.train_encode_dataset.TrainEncodeDatasetModel {
    n_epochs: 20,
    report_stats_every_n_steps: 1000,
    save_track_metrics_during_training: True,
    save_checkpoint_every_n_steps: 5000,
    report_gt_feature_n_positives: 10,
    device: 'cuda:2',
    data_parallel: False,
    logging_verbosity: 2,
    log_confusion_matrix: False,
    metrics: {
        average_precision: !import sklearn.metrics.average_precision_score,
        average_precision_masked: !import sklearn.metrics.average_precision_score,
        r2: !import sklearn.metrics.r2_score,
        r2_masked: !import sklearn.metrics.r2_score,
    },
    metrics_transforms: {
        average_precision: *quant2prob_transform,
        average_precision_masked: *quant2prob_transform_masked_tracks,
        r2: *batch_merging_transform,
        r2_masked: *batch_merging_transform_masked_tracks,
    }
}

criterion: !obj:src.criterion.WeightedMSELossWithMPI {alpha: 0.0002}
output_dir: /home/jovyan/datasets/DeepCT/DeepCT_outputs/final/2022-noMask_seed42/

random_seed: 42
create_subdirectory: True
...
